<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>6 Logistische Regression | Statistik in R: eine Einführung für PhonetikerInnen</title>
  <meta name="description" content="Eine Einführung in die Statistik mit R mit Fokus auf lineare Regressionen. Diese Einführung wurde als Lehrmaterial für die Studierenden des Instituts für Phonetik und Sprachverarbeitung der LMU konzipiert." />
  <meta name="generator" content="bookdown 0.44 and GitBook 2.6.7" />

  <meta property="og:title" content="6 Logistische Regression | Statistik in R: eine Einführung für PhonetikerInnen" />
  <meta property="og:type" content="book" />
  
  <meta property="og:description" content="Eine Einführung in die Statistik mit R mit Fokus auf lineare Regressionen. Diese Einführung wurde als Lehrmaterial für die Studierenden des Instituts für Phonetik und Sprachverarbeitung der LMU konzipiert." />
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="6 Logistische Regression | Statistik in R: eine Einführung für PhonetikerInnen" />
  
  <meta name="twitter:description" content="Eine Einführung in die Statistik mit R mit Fokus auf lineare Regressionen. Diese Einführung wurde als Lehrmaterial für die Studierenden des Instituts für Phonetik und Sprachverarbeitung der LMU konzipiert." />
  

<meta name="author" content="Johanna Cronenberg" />


<meta name="date" content="2025-09-28" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="gemischte-lineare-regression.html"/>

<script src="libs/jquery/jquery-3.6.0.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
<link href="libs/gitbook/css/style.css" rel="stylesheet" />
<link href="libs/gitbook/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook/css/plugin-clipboard.css" rel="stylesheet" />








<link href="libs/anchor-sections/anchor-sections.css" rel="stylesheet" />
<link href="libs/anchor-sections/anchor-sections-hash.css" rel="stylesheet" />
<script src="libs/anchor-sections/anchor-sections.js"></script>


<style type="text/css">
html { -webkit-text-size-adjust: 100%; }
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { color: #008000; } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { color: #008000; font-weight: bold; } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<style type="text/css">
  
  div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./index.html">Statistik in R: eine Einführung</a></li>

<li class="divider"></li>
<li class="chapter" data-level="1" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i><b>1</b> Setup</a>
<ul>
<li class="chapter" data-level="1.1" data-path="index.html"><a href="index.html#installation-und-kursverzeichnis"><i class="fa fa-check"></i><b>1.1</b> Installation und Kursverzeichnis</a></li>
<li class="chapter" data-level="1.2" data-path="index.html"><a href="index.html#r-projekte"><i class="fa fa-check"></i><b>1.2</b> R Projekte</a></li>
<li class="chapter" data-level="1.3" data-path="index.html"><a href="index.html#packages-und-r-version"><i class="fa fa-check"></i><b>1.3</b> Packages und R Version</a></li>
<li class="chapter" data-level="1.4" data-path="index.html"><a href="index.html#sessions"><i class="fa fa-check"></i><b>1.4</b> Sessions</a></li>
<li class="chapter" data-level="1.5" data-path="index.html"><a href="index.html#dokumentarten"><i class="fa fa-check"></i><b>1.5</b> Dokumentarten</a>
<ul>
<li class="chapter" data-level="1.5.1" data-path="index.html"><a href="index.html#r-skripte"><i class="fa fa-check"></i><b>1.5.1</b> R Skripte</a></li>
<li class="chapter" data-level="1.5.2" data-path="index.html"><a href="index.html#r-markdown"><i class="fa fa-check"></i><b>1.5.2</b> R Markdown</a></li>
</ul></li>
<li class="chapter" data-level="1.6" data-path="index.html"><a href="index.html#hilfe-zur-selbsthilfe"><i class="fa fa-check"></i><b>1.6</b> Hilfe zur Selbsthilfe</a>
<ul>
<li class="chapter" data-level="1.6.1" data-path="index.html"><a href="index.html#fehler-erkennen"><i class="fa fa-check"></i><b>1.6.1</b> Fehler erkennen</a></li>
<li class="chapter" data-level="1.6.2" data-path="index.html"><a href="index.html#community-nutzen"><i class="fa fa-check"></i><b>1.6.2</b> Community nutzen</a></li>
<li class="chapter" data-level="1.6.3" data-path="index.html"><a href="index.html#hilfe-zu-ggplot2"><i class="fa fa-check"></i><b>1.6.3</b> Hilfe zu <code>ggplot2</code></a></li>
<li class="chapter" data-level="1.6.4" data-path="index.html"><a href="index.html#statistik-in-r-literatur"><i class="fa fa-check"></i><b>1.6.4</b> Statistik in R: Literatur</a></li>
</ul></li>
<li class="chapter" data-level="1.7" data-path="index.html"><a href="index.html#acknowledgements"><i class="fa fa-check"></i><b>1.7</b> Acknowledgements</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="05_logistischeRegression.html"><a href="#einf%C3%BChrung-in-die-inferenzstatistik"><i class="fa fa-check"></i><b>2</b> Einführung in die Inferenzstatistik</a>
<ul>
<li class="chapter" data-level="2.1" data-path="einführung-in-die-inferenzstatistik.html"><a href="einführung-in-die-inferenzstatistik.html"><i class="fa fa-check"></i><b>2.1</b> Packages und Daten laden</a></li>
<li class="chapter" data-level="2.2" data-path="einführung-in-die-inferenzstatistik.html"><a href="einführung-in-die-inferenzstatistik.html#grundbegriffe"><i class="fa fa-check"></i><b>2.2</b> Grundbegriffe</a></li>
<li class="chapter" data-level="2.3" data-path="einführung-in-die-inferenzstatistik.html"><a href="einführung-in-die-inferenzstatistik.html#normalverteilung"><i class="fa fa-check"></i><b>2.3</b> Normalverteilung</a>
<ul>
<li class="chapter" data-level="2.3.1" data-path="einführung-in-die-inferenzstatistik.html"><a href="einführung-in-die-inferenzstatistik.html#auf-normalverteilung-testen"><i class="fa fa-check"></i><b>2.3.1</b> Auf Normalverteilung testen</a></li>
<li class="chapter" data-level="2.3.2" data-path="einführung-in-die-inferenzstatistik.html"><a href="einführung-in-die-inferenzstatistik.html#regel-konfidenzintervalle"><i class="fa fa-check"></i><b>2.3.2</b> 68–95–99.7 Regel &amp; Konfidenzintervalle</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="3" data-path="einfache-lineare-regression.html"><a href="einfache-lineare-regression.html"><i class="fa fa-check"></i><b>3</b> Einfache lineare Regression</a>
<ul>
<li class="chapter" data-level="3.1" data-path="einfache-lineare-regression.html"><a href="einfache-lineare-regression.html#packages-und-daten-laden-1"><i class="fa fa-check"></i><b>3.1</b> Packages und Daten laden</a></li>
<li class="chapter" data-level="3.2" data-path="05_logistischeRegression.html"><a href="#einf%C3%BChrung"><i class="fa fa-check"></i><b>3.2</b> Einführung</a></li>
<li class="chapter" data-level="3.3" data-path="einfache-lineare-regression.html"><a href="einfache-lineare-regression.html#korrelation"><i class="fa fa-check"></i><b>3.3</b> Korrelation</a></li>
<li class="chapter" data-level="3.4" data-path="einfache-lineare-regression.html"><a href="einfache-lineare-regression.html#die-regressionslinie"><i class="fa fa-check"></i><b>3.4</b> Die Regressionslinie</a>
<ul>
<li class="chapter" data-level="3.4.1" data-path="einfache-lineare-regression.html"><a href="einfache-lineare-regression.html#theoretische-informationen"><i class="fa fa-check"></i><b>3.4.1</b> Theoretische Informationen</a></li>
<li class="chapter" data-level="3.4.2" data-path="einfache-lineare-regression.html"><a href="einfache-lineare-regression.html#regressionslinien-mit-ggplot2"><i class="fa fa-check"></i><b>3.4.2</b> Regressionslinien mit <code>ggplot2</code></a></li>
</ul></li>
<li class="chapter" data-level="3.5" data-path="einfache-lineare-regression.html"><a href="einfache-lineare-regression.html#lineare-regression-mit-lm"><i class="fa fa-check"></i><b>3.5</b> Lineare Regression mit <code>lm()</code></a></li>
<li class="chapter" data-level="3.6" data-path="einfache-lineare-regression.html"><a href="einfache-lineare-regression.html#residuals"><i class="fa fa-check"></i><b>3.6</b> Residuals</a></li>
<li class="chapter" data-level="3.7" data-path="05_logistischeRegression.html"><a href="#annahmen-%C3%BCberpr%C3%BCfen"><i class="fa fa-check"></i><b>3.7</b> Annahmen überprüfen</a>
<ul>
<li class="chapter" data-level="3.7.1" data-path="05_logistischeRegression.html"><a href="#normalit%C3%A4t-der-residuals"><i class="fa fa-check"></i><b>3.7.1</b> Normalität der Residuals</a></li>
<li class="chapter" data-level="3.7.2" data-path="einfache-lineare-regression.html"><a href="einfache-lineare-regression.html#konstante-varianz-der-residuals"><i class="fa fa-check"></i><b>3.7.2</b> Konstante Varianz der Residuals</a></li>
</ul></li>
<li class="chapter" data-level="3.8" data-path="einfache-lineare-regression.html"><a href="einfache-lineare-regression.html#alle-ergebnisse-von-lm-verstehen"><i class="fa fa-check"></i><b>3.8</b> Alle Ergebnisse von <code>lm()</code> verstehen</a>
<ul>
<li class="chapter" data-level="3.8.1" data-path="05_logistischeRegression.html"><a href="#gesch%C3%A4tzte-y-werte-und-residuals"><i class="fa fa-check"></i><b>3.8.1</b> Geschätzte y-Werte und Residuals</a></li>
<li class="chapter" data-level="3.8.2" data-path="einfache-lineare-regression.html"><a href="einfache-lineare-regression.html#regressionskoeffizienten-und-t-statistik"><i class="fa fa-check"></i><b>3.8.2</b> Regressionskoeffizienten und t-Statistik</a></li>
<li class="chapter" data-level="3.8.3" data-path="05_logistischeRegression.html"><a href="#g%C3%BCtekriterien-f%C3%BCr-das-modell-und-f-statistik"><i class="fa fa-check"></i><b>3.8.3</b> Gütekriterien für das Modell und F-Statistik</a></li>
</ul></li>
<li class="chapter" data-level="3.9" data-path="einfache-lineare-regression.html"><a href="einfache-lineare-regression.html#ergebnis-berichten"><i class="fa fa-check"></i><b>3.9</b> Ergebnis berichten</a></li>
<li class="chapter" data-level="3.10" data-path="einfache-lineare-regression.html"><a href="einfache-lineare-regression.html#zusammenfassung"><i class="fa fa-check"></i><b>3.10</b> Zusammenfassung</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="multiple-lineare-regression.html"><a href="multiple-lineare-regression.html"><i class="fa fa-check"></i><b>4</b> Multiple Lineare Regression</a>
<ul>
<li class="chapter" data-level="4.1" data-path="multiple-lineare-regression.html"><a href="multiple-lineare-regression.html#packages-und-daten-laden-2"><i class="fa fa-check"></i><b>4.1</b> Packages und Daten laden</a></li>
<li class="chapter" data-level="4.2" data-path="05_logistischeRegression.html"><a href="#einf%C3%BChrung-1"><i class="fa fa-check"></i><b>4.2</b> Einführung</a></li>
<li class="chapter" data-level="4.3" data-path="05_logistischeRegression.html"><a href="#kontinuierliche-unabh%C3%A4ngige-variablen"><i class="fa fa-check"></i><b>4.3</b> Kontinuierliche unabhängige Variablen</a>
<ul>
<li class="chapter" data-level="4.3.1" data-path="multiple-lineare-regression.html"><a href="multiple-lineare-regression.html#ohne-interaktion"><i class="fa fa-check"></i><b>4.3.1</b> Ohne Interaktion</a></li>
<li class="chapter" data-level="4.3.2" data-path="multiple-lineare-regression.html"><a href="multiple-lineare-regression.html#mit-interaktion"><i class="fa fa-check"></i><b>4.3.2</b> Mit Interaktion</a></li>
</ul></li>
<li class="chapter" data-level="4.4" data-path="05_logistischeRegression.html"><a href="#kategorische-unabh%C3%A4ngige-variablen"><i class="fa fa-check"></i><b>4.4</b> Kategorische unabhängige Variablen</a>
<ul>
<li class="chapter" data-level="4.4.1" data-path="multiple-lineare-regression.html"><a href="multiple-lineare-regression.html#ohne-interaktion-1"><i class="fa fa-check"></i><b>4.4.1</b> Ohne Interaktion</a></li>
<li class="chapter" data-level="4.4.2" data-path="multiple-lineare-regression.html"><a href="multiple-lineare-regression.html#mit-interaktion-1"><i class="fa fa-check"></i><b>4.4.2</b> Mit Interaktion</a></li>
</ul></li>
<li class="chapter" data-level="4.5" data-path="05_logistischeRegression.html"><a href="#mix-aus-kontinuierlichen-und-kategorischen-unabh%C3%A4ngigen-variablen"><i class="fa fa-check"></i><b>4.5</b> Mix aus kontinuierlichen und kategorischen unabhängigen Variablen</a>
<ul>
<li class="chapter" data-level="4.5.1" data-path="multiple-lineare-regression.html"><a href="multiple-lineare-regression.html#ohne-interaktion-2"><i class="fa fa-check"></i><b>4.5.1</b> Ohne Interaktion</a></li>
<li class="chapter" data-level="4.5.2" data-path="multiple-lineare-regression.html"><a href="multiple-lineare-regression.html#mit-interaktion-2"><i class="fa fa-check"></i><b>4.5.2</b> Mit Interaktion</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="5" data-path="gemischte-lineare-regression.html"><a href="gemischte-lineare-regression.html"><i class="fa fa-check"></i><b>5</b> Gemischte Lineare Regression</a>
<ul>
<li class="chapter" data-level="5.1" data-path="gemischte-lineare-regression.html"><a href="gemischte-lineare-regression.html#packages-und-daten-laden-3"><i class="fa fa-check"></i><b>5.1</b> Packages und Daten laden</a></li>
<li class="chapter" data-level="5.2" data-path="05_logistischeRegression.html"><a href="#mixed-models-lmers-einf%C3%BChrung"><i class="fa fa-check"></i><b>5.2</b> Mixed Models (LMERs): Einführung</a></li>
<li class="chapter" data-level="5.3" data-path="gemischte-lineare-regression.html"><a href="gemischte-lineare-regression.html#random-intercepts-vs.-random-slopes"><i class="fa fa-check"></i><b>5.3</b> Random Intercepts vs. Random Slopes</a>
<ul>
<li class="chapter" data-level="5.3.1" data-path="gemischte-lineare-regression.html"><a href="gemischte-lineare-regression.html#random-intercepts"><i class="fa fa-check"></i><b>5.3.1</b> Random Intercepts</a></li>
<li class="chapter" data-level="5.3.2" data-path="gemischte-lineare-regression.html"><a href="gemischte-lineare-regression.html#random-slopes"><i class="fa fa-check"></i><b>5.3.2</b> Random Slopes</a></li>
<li class="chapter" data-level="5.3.3" data-path="05_logistischeRegression.html"><a href="#random-effects-struktur-f%C3%BCr-word-bestimmen"><i class="fa fa-check"></i><b>5.3.3</b> Random Effects Struktur für <code>word</code> bestimmen</a></li>
</ul></li>
<li class="chapter" data-level="5.4" data-path="gemischte-lineare-regression.html"><a href="gemischte-lineare-regression.html#lmer-in-r"><i class="fa fa-check"></i><b>5.4</b> LMER in R</a>
<ul>
<li class="chapter" data-level="5.4.1" data-path="gemischte-lineare-regression.html"><a href="gemischte-lineare-regression.html#fixed-effects"><i class="fa fa-check"></i><b>5.4.1</b> Fixed Effects</a></li>
<li class="chapter" data-level="5.4.2" data-path="gemischte-lineare-regression.html"><a href="gemischte-lineare-regression.html#random-effects"><i class="fa fa-check"></i><b>5.4.2</b> Random Effects</a></li>
</ul></li>
<li class="chapter" data-level="5.5" data-path="gemischte-lineare-regression.html"><a href="gemischte-lineare-regression.html#konvergenzprobleme-und-modell-vereinfachen"><i class="fa fa-check"></i><b>5.5</b> Konvergenzprobleme und Modell vereinfachen</a></li>
<li class="chapter" data-level="5.6" data-path="gemischte-lineare-regression.html"><a href="gemischte-lineare-regression.html#ergebnisse-berichten"><i class="fa fa-check"></i><b>5.6</b> Ergebnisse berichten</a></li>
<li class="chapter" data-level="5.7" data-path="05_logistischeRegression.html"><a href="#g%C3%BCtekriterien-f%C3%BCr-mixed-models"><i class="fa fa-check"></i><b>5.7</b> Gütekriterien für Mixed Models</a>
<ul>
<li class="chapter" data-level="5.7.1" data-path="gemischte-lineare-regression.html"><a href="gemischte-lineare-regression.html#marginal-und-conditional-r2"><i class="fa fa-check"></i><b>5.7.1</b> Marginal und Conditional <span class="math inline">\(R^2\)</span></a></li>
<li class="chapter" data-level="5.7.2" data-path="gemischte-lineare-regression.html"><a href="gemischte-lineare-regression.html#likelihood-ratio-tests"><i class="fa fa-check"></i><b>5.7.2</b> Likelihood Ratio Tests</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="6" data-path="logistische-regression.html"><a href="logistische-regression.html"><i class="fa fa-check"></i><b>6</b> Logistische Regression</a>
<ul>
<li class="chapter" data-level="6.1" data-path="logistische-regression.html"><a href="logistische-regression.html#setup-und-pakete-laden"><i class="fa fa-check"></i><b>6.1</b> Setup und Pakete laden</a></li>
<li class="chapter" data-level="6.2" data-path="logistische-regression.html"><a href="logistische-regression.html#von-der-linearen-zur-logistischen-regression"><i class="fa fa-check"></i><b>6.2</b> Von der linearen zur logistischen Regression</a>
<ul>
<li class="chapter" data-level="6.2.1" data-path="05_logistischeRegression.html"><a href="#ein-beispiel-f%C3%BCr-p-q-und-logit"><i class="fa fa-check"></i><b>6.2.1</b> Ein Beispiel für <span class="math inline">\(P\)</span>, <span class="math inline">\(Q\)</span> und Logit</a></li>
<li class="chapter" data-level="6.2.2" data-path="logistische-regression.html"><a href="logistische-regression.html#die-logistische-regressionslinie"><i class="fa fa-check"></i><b>6.2.2</b> Die logistische Regressionslinie</a></li>
<li class="chapter" data-level="6.2.3" data-path="logistische-regression.html"><a href="logistische-regression.html#regression-mit-glm"><i class="fa fa-check"></i><b>6.2.3</b> Regression mit <code>glm()</code></a></li>
<li class="chapter" data-level="6.2.4" data-path="logistische-regression.html"><a href="logistische-regression.html#der-chi-square-test-ergebnisse-berichten"><i class="fa fa-check"></i><b>6.2.4</b> Der Chi-Square Test &amp; Ergebnisse berichten</a></li>
</ul></li>
<li class="chapter" data-level="6.3" data-path="logistische-regression.html"><a href="logistische-regression.html#die-sigmoidal-funktion-und-der-umkipppunkt"><i class="fa fa-check"></i><b>6.3</b> Die Sigmoidal-Funktion und der Umkipppunkt</a>
<ul>
<li class="chapter" data-level="6.3.1" data-path="logistische-regression.html"><a href="logistische-regression.html#der-umkipppunkt"><i class="fa fa-check"></i><b>6.3.1</b> Der Umkipppunkt</a></li>
<li class="chapter" data-level="6.3.2" data-path="logistische-regression.html"><a href="logistische-regression.html#proportionen-abbilden"><i class="fa fa-check"></i><b>6.3.2</b> Proportionen abbilden</a></li>
</ul></li>
<li class="chapter" data-level="6.4" data-path="logistische-regression.html"><a href="logistische-regression.html#umkipppunkte-in-perzeptionstests"><i class="fa fa-check"></i><b>6.4</b> Umkipppunkte in Perzeptionstests</a></li>
<li class="chapter" data-level="6.5" data-path="05_logistischeRegression.html"><a href="#kategorialer-unabh%C3%A4ngiger-faktor"><i class="fa fa-check"></i><b>6.5</b> Kategorialer unabhängiger Faktor</a></li>
</ul></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Statistik in R: eine Einführung für PhonetikerInnen</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="logistische-regression" class="section level1 hasAnchor" number="6">
<h1><span class="header-section-number">6</span> Logistische Regression<a href="logistische-regression.html#logistische-regression" class="anchor-section" aria-label="Anchor link to header"></a></h1>
<div id="setup-und-pakete-laden" class="section level2 hasAnchor" number="6.1">
<h2><span class="header-section-number">6.1</span> Setup und Pakete laden<a href="logistische-regression.html#setup-und-pakete-laden" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Öffnen Sie das R Projekt, das Sie für diesen Kurs angelegt haben. Öffnen Sie hierfür RStudio und benutzen Sie die Schaltfläche oben rechts oder navigieren Sie zu Ihrem Kursverzeichnis und klicken Sie auf die <code>.Rproj</code> Datei.</p>
<p>Laden Sie das <code>tidyverse</code>:</p>
<div class="sourceCode" id="cb341"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb341-1"><a href="logistische-regression.html#cb341-1" tabindex="-1"></a><span class="fu">library</span>(tidyverse)</span></code></pre></div>
<p>Laden Sie außerdem die folgenden Data Frames:</p>
<div class="sourceCode" id="cb342"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb342-1"><a href="logistische-regression.html#cb342-1" tabindex="-1"></a>url <span class="ot">&lt;-</span> <span class="st">&quot;http://www.phonetik.uni-muenchen.de/~jmh/lehre/Rdf&quot;</span></span>
<span id="cb342-2"><a href="logistische-regression.html#cb342-2" tabindex="-1"></a>ovokal <span class="ot">&lt;-</span> <span class="fu">read.table</span>(<span class="fu">file.path</span>(url, <span class="st">&quot;ovokal.txt&quot;</span>))</span>
<span id="cb342-3"><a href="logistische-regression.html#cb342-3" tabindex="-1"></a>pvp <span class="ot">&lt;-</span> <span class="fu">read.table</span>(<span class="fu">file.path</span>(url, <span class="st">&quot;pvp.txt&quot;</span>))</span>
<span id="cb342-4"><a href="logistische-regression.html#cb342-4" tabindex="-1"></a>sz <span class="ot">&lt;-</span> <span class="fu">read.table</span>(<span class="fu">file.path</span>(url, <span class="st">&quot;sz.txt&quot;</span>))</span></code></pre></div>
</div>
<div id="von-der-linearen-zur-logistischen-regression" class="section level2 hasAnchor" number="6.2">
<h2><span class="header-section-number">6.2</span> Von der linearen zur logistischen Regression<a href="logistische-regression.html#von-der-linearen-zur-logistischen-regression" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Die logistische Regression ist (genau wie die lineare Regression) ein statistischer Test, der prüft, ob eine abhängige Variable von einem unabhängigen Faktor beeinflusst wird. Der Unterschied zur linearen Regression ist, dass die abhängige Variable in der logistischen Regression immer <strong>kategorial und binär</strong> ist und die unabhängige Variable entweder <strong>numerisch (kontinuierlich) oder kategorial</strong> sein kann. Mit der logistischen Regression können wir unter der Annahme eines Zusammenhangs zwischen abhängiger und unabhängiger Variable die Wahrscheinlichkeit eines bestimmten Wertes schätzen.</p>
<p>Beispiele:</p>
<ul>
<li>Inwiefern wird die Vokalisierung von einem finalen /l/ im Englischen (<em>feel</em> vs. ‘<em>feeu</em>’)
vom Dialekt beeinflusst?
<ul>
<li>Abhängige Variable: Vokalisierung (kategorial mit zwei Stufen: ja, nein)</li>
<li>Unabhängige Variable: Dialekt (kategorial mit zwei oder mehr Stufen)</li>
</ul></li>
<li>Wird “passt” in Augsburg im Vergleich zu München eher mit /ʃ/ produziert?
<ul>
<li>Abhängige Variable: Frikativ (kategorial mit zwei Stufen: /s/, /ʃ/)</li>
<li>Unabhängige Variable: Dialekt (kategorial mit zwei Stufen: Augsburg, München)</li>
</ul></li>
<li>Der Vokal /a/ in /lam/ wird mit unterschiedlichen Dauern synthetisiert und Hörern vorgespielt. Hören die Probanden eher “lahm” (langes /a:/) als “Lamm” (kurzes /a/) mit zunehmender Dauer des Vokals?
<ul>
<li>Abhängige Variable: Vokal (kategorial mit zwei Stufen: /a/, /a:/)</li>
<li>Unabhängige Variable: Dauer (kontinuierlich)</li>
</ul></li>
</ul>
<p>Da die abhängige Variable in der logistischen Regression immer ein Faktor mit zwei Stufen ist, kann man diese Stufen auch als 1 und 0 kodieren und fragen, was auf der Grundlage der gegebenen Daten die Wahrscheinlichkeit <span class="math inline">\(P\)</span> ist, dass die abhängige Variable <span class="math inline">\(y\)</span> den Wert 1 annimmt: <span class="math inline">\(P(y = 1)\)</span>. Genauso können wir nach der Wahrscheinlichkeit <span class="math inline">\(Q\)</span> fragen, dass <span class="math inline">\(y\)</span> den Wert 0 annimmt: <span class="math inline">\(1 - P(y = 1)\)</span>. Für das dritte Beispiel oben würde das folgendes bedeuten:</p>
<ul>
<li><span class="math inline">\(P\)</span>: Wahrscheinlichkeit, dass Probanden mit steigender Vokaldauer “lahm” hören (“Erfolg”, denn auf der Grundlage unseres Wissens oder unserer bisherigen Erkenntnisse z.B. aus anderen Experimenten gehen wir davon aus, dass die Probanden bei steigender Vokaldauer “lahm” hören sollten)</li>
<li><span class="math inline">\(Q\)</span>: Wahrscheinlichkeit, dass Probanden mit steigender Vokaldauer “Lamm” hören (“Misserfolg”, denn wieder auf der Grundlage unserer bisherigen Erkenntnisse zu diesem Sachverhalt gehen wir davon aus, dass es seltsam wäre, wenn die Probanden bei steigender Vokaldauer “Lamm” hören würden)</li>
</ul>
<p>Die Division (das Verhältnis) von <span class="math inline">\(P\)</span> und <span class="math inline">\(Q\)</span> wird als <strong>Odds</strong> (Gewinnchancen) bezeichnet:</p>
<p><span class="math inline">\(Odds = \frac{P(y = 1)}{1 - P(y = 1)} = \frac{P}{Q}\)</span></p>
<p>Die Gewinnchancen liegen immer in einem Wertebereich von 0 bis unendlich. Nun könnte man überlegen, einfach die <em>Odds</em> als abhängige Variable in einer linearen Regression zu verwenden, denn jetzt handelt es sich ja nicht mehr um eine kategoriale, binäre abhängige Variable. Das Problem ist, dass <code>lm()</code> nicht weiß, dass die <em>Odds</em> nur Werte von Null bis Unendlich annehmen können und daher auch Werte außerhalb dieses Bereichs vorhersagen würde. Außerdem sagt das Verhältnis von <span class="math inline">\(P\)</span> und <span class="math inline">\(Q\)</span> nichts darüber aus, wie viele Beobachtungen in die Berechnung dieses Verhältnisses eingeflossen sind (je mehr Beobachtungen, desto aussagekräftiger ist die berechnete Gewinnchance). Wir brauchen also eine Funktion, die uns die <em>Odds</em> in etwas umwandelt, dass zum einen in den Wertebereich <span class="math inline">\(±\)</span>unendlich fällt und zum anderen die Proportionen anhand der Anzahl der Beobachtungen gewichtet. Diese Funktion heißt allgemein <strong>Linkfunktion</strong> (<em>link function</em>) und ist im Fall der logistischen Regression die <strong>Logit Transformation der Odds</strong>. Der Logit ist der Logarithmus der Gewinnchancen und wird deshalb auch als <strong>log odds</strong> bezeichnet:</p>
<p><span class="math inline">\(log(\frac{P}{Q})\)</span></p>
<div id="ein-beispiel-für-p-q-und-logit" class="section level3 hasAnchor" number="6.2.1">
<h3><span class="header-section-number">6.2.1</span> Ein Beispiel für <span class="math inline">\(P\)</span>, <span class="math inline">\(Q\)</span> und Logit<a href="#ein-beispiel-f%C3%BCr-p-q-und-logit" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Zwischen 1950 und 2005 sollen Wörter wie <em>lost</em> in einer aristokratischen Form des Englischen (<em>Received Pronunciation</em>) immer weniger mit einem hohen Vokal /lo:st/ und zunehmend mit einem tiefen Vokal /lɔst/ produziert worden sein. Für diese Vermutung haben wir Daten im Data Frame <code>ovokal</code>:</p>
<div class="sourceCode" id="cb343"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb343-1"><a href="logistische-regression.html#cb343-1" tabindex="-1"></a><span class="fu">head</span>(ovokal)</span></code></pre></div>
<pre><code>##   Jahr Vokal Vpn
## 1 1950  hoch  S1
## 2 1950  hoch  S2
## 3 1950  hoch  S3
## 4 1950  hoch  S4
## 5 1950  hoch  S5
## 6 1950  hoch  S6</code></pre>
<p>Unsere Forschungsfrage lautet: <em>Wird die Aussprache des Vokals (hoch vs. tief = abhängige Variable) vom Jahr (1950… 2005 = unabhängige numerische Variable) beeinflusst?</em></p>
<p>Wir wollen <span class="math inline">\(P\)</span> (die Wahrscheinlichkeit, dass der Vokal tief produziert wurde) und <span class="math inline">\(Q\)</span> (die Wahrscheinlichkeit, dass der Vokal hoch produziert wurde) pro Jahr berechnen. Unseren bisherigen Erkenntnissen nach ist die Richtung der Veränderung von der hohen hin zur tiefen Aussprache des Vokals /o/, also bezeichnen wir es als “Erfolg”, wenn der Vokal tief produziert wurde, und als “Misserfolg”, wenn er hoch produziert wurde. Wir kodieren nun als ersten Schritt in der Berechnung von <span class="math inline">\(P\)</span> und <span class="math inline">\(Q\)</span> tiefe und hohe Aussprache als 1 und 0, bzw. als <code>TRUE</code> und <code>FALSE</code>:</p>
<div class="sourceCode" id="cb345"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb345-1"><a href="logistische-regression.html#cb345-1" tabindex="-1"></a>ovokal<span class="sc">$</span>Erfolg <span class="ot">&lt;-</span> ovokal<span class="sc">$</span>Vokal <span class="sc">==</span> <span class="st">&quot;tief&quot;</span></span>
<span id="cb345-2"><a href="logistische-regression.html#cb345-2" tabindex="-1"></a>ovokal<span class="sc">$</span>Misserfolg <span class="ot">&lt;-</span> <span class="sc">!</span>ovokal<span class="sc">$</span>Erfolg</span>
<span id="cb345-3"><a href="logistische-regression.html#cb345-3" tabindex="-1"></a><span class="fu">head</span>(ovokal)</span></code></pre></div>
<pre><code>##   Jahr Vokal Vpn Erfolg Misserfolg
## 1 1950  hoch  S1  FALSE       TRUE
## 2 1950  hoch  S2  FALSE       TRUE
## 3 1950  hoch  S3  FALSE       TRUE
## 4 1950  hoch  S4  FALSE       TRUE
## 5 1950  hoch  S5  FALSE       TRUE
## 6 1950  hoch  S6  FALSE       TRUE</code></pre>
<p>Dann nehmen wir uns das erste Jahr vor, 1950, und berechnen hierfür <span class="math inline">\(P\)</span> und <span class="math inline">\(Q\)</span>, indem wir zählen, wie viele “Erfolge” bzw. “Misserfolge” wir für dieses Jahr haben:</p>
<div class="sourceCode" id="cb347"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb347-1"><a href="logistische-regression.html#cb347-1" tabindex="-1"></a>jahr_1950 <span class="ot">&lt;-</span> ovokal[ovokal<span class="sc">$</span>Jahr <span class="sc">==</span> <span class="dv">1950</span>,]</span>
<span id="cb347-2"><a href="logistische-regression.html#cb347-2" tabindex="-1"></a>P <span class="ot">&lt;-</span> <span class="fu">sum</span>(jahr_1950<span class="sc">$</span>Erfolg)</span>
<span id="cb347-3"><a href="logistische-regression.html#cb347-3" tabindex="-1"></a>P</span></code></pre></div>
<pre><code>## [1] 5</code></pre>
<div class="sourceCode" id="cb349"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb349-1"><a href="logistische-regression.html#cb349-1" tabindex="-1"></a>Q <span class="ot">&lt;-</span> <span class="fu">sum</span>(jahr_1950<span class="sc">$</span>Misserfolg)</span>
<span id="cb349-2"><a href="logistische-regression.html#cb349-2" tabindex="-1"></a>Q</span></code></pre></div>
<pre><code>## [1] 30</code></pre>
<p>Das heißt im Jahr 1950 wurde der Vokal /o/ in Wörtern wie <em>lost</em> nur 5 Mal tief, aber 30 Mal hoch produziert. So müssten wir das jetzt für jede Stufe der unabhängigen Variable (für jede Jahreszahl) machen… Aber das wäre sehr umständlich. Wir nutzen deshalb das Paket <code>dplyr</code> aus dem <code>tidyverse</code>. Das bietet eine elegante Schreibweise und sehr viele hilfreiche Funktionen für den Umgang mit Daten.</p>
<div class="sourceCode" id="cb351"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb351-1"><a href="logistische-regression.html#cb351-1" tabindex="-1"></a>df <span class="ot">&lt;-</span> ovokal <span class="sc">%&gt;%</span></span>
<span id="cb351-2"><a href="logistische-regression.html#cb351-2" tabindex="-1"></a>  <span class="fu">group_by</span>(Jahr) <span class="sc">%&gt;%</span></span>
<span id="cb351-3"><a href="logistische-regression.html#cb351-3" tabindex="-1"></a>  dplyr<span class="sc">::</span><span class="fu">summarise</span>(<span class="at">P =</span> <span class="fu">sum</span>(Erfolg), <span class="at">Q =</span> <span class="fu">sum</span>(Misserfolg))</span>
<span id="cb351-4"><a href="logistische-regression.html#cb351-4" tabindex="-1"></a>df</span></code></pre></div>
<pre><code>## # A tibble: 6 × 3
##    Jahr     P     Q
##   &lt;int&gt; &lt;int&gt; &lt;int&gt;
## 1  1950     5    30
## 2  1960    21    18
## 3  1971    26    15
## 4  1980    20    13
## 5  1993    32     4
## 6  2005    34     2</code></pre>
<div class="gray">
<p><strong>Erklärung: dplyr</strong></p>
<p>Im <code>tidyverse</code> lassen sich Funktionen mit der Pipe <code>%&gt;%</code> aneinanderhängen. Oft wird dabei zuerst der Data Frame genannt, denn danach können alle Spalten aus dem Data Frame einfach per Spaltennamen in den Funktionen verwendet werden. Im obigen Code nutzen wir zwei Funktionen nacheinander, die häufig gemeinsam verwendet werden: <code>group_by()</code> gruppiert die Zeilen im Data Frame nach den in den runden Klammern genannten Spalten. Bei uns wird nach der unabhängigen Variable <code>Jahr</code> gruppiert. Alle darauf folgenden Funktion werden nicht mehr auf den gesamten Data Frame, sondern nur noch auf die einzelnen Gruppen (Gruppe = alle Beobachtungen, die zu einer Jahreszahl gehören) angewendet. Dieser Vorgang ist quasi unsichtbar, er kommt erst durch die zweite Funktion zum Tragen.</p>
<p><code>summarise()</code> kann verwendet werden, um zusammenfassende Funktionen wie <code>sum()</code>, <code>mean()</code>, <code>median()</code>, <code>min()</code>, <code>max()</code>, usw. auf Variablen anzuwenden und das Ergebnis sofort in einer neuen Spalte abzuspeichern. Bei <code>summarise()</code> empfehlen wir, grundsätzlich mit <code>dplyr::</code> anzugeben, dass die <code>summarise()</code>-Funktion aus dem <code>dplyr</code> Paket verwendet werden soll, denn es gibt leider sogar innerhalb des <code>tidyverse</code> noch andere Packages, die eine <code>summarise()</code>-Funktion haben. In der <code>summarise()</code>-Funktion geben wir zuerst den Namen der neu zu erstellenden Spalte an, z.B. <code>P</code>, und anschließend können wir eine zusammenfassende Funktion wie <code>sum()</code> auf eine der Spalten in unserem Data Frame anwenden, z.B. <code>sum(Erfolg)</code>. Das zählt dann für jede Jahreszahl, wie viele TRUE-Werte es in <code>ovokal$Erfolg</code> gibt.</p>
<p>Sie sehen, dass das Ergebnis ein Data Frame (bzw. eine <code>tibble</code>) mit sechs Zeilen ist, eine Zeile pro Jahr (weil wir nach Jahr gruppiert haben) und dann gibt es noch unsere zwei neu erstellten Spalten <code>P</code> und <code>Q</code>. Alle anderen Spalten aus dem ursprünglichen Data Frame wurden fallen gelassen.</p>
<p>Die erste Zeile in unserem neuen Data Frame <code>df</code> bedeutet folglich, dass /o/ im Jahr 1950 fünf Mal tief und 30 Mal hoch produziert wurde. Die zweite Zeile zeigt, dass die Probanden im Jahr 1960 den Vokal bereits öfter tief (P ist 21) als hoch (Q ist 18) produziert haben, usw.</p>
<p>Sie werden in diesem Kurs selbst keinen <code>dplyr</code>-Code schreiben müssen, aber Sie sollten ihn lesen können. In diesem <a href="https://rstudio.com/wp-content/uploads/2015/02/data-wrangling-cheatsheet.pdf">Cheat Sheet</a> finden Sie eine knappe Übersicht über <code>dplyr</code> und in <a href="https://r4ds.had.co.nz/transform.html#grouped-summaries-with-summarise">Hadley Wickham’s Buch</a> finden Sie sehr viele weitere Informationen und Beispiele, die Ihnen beim Umgang mit <code>dplyr</code> helfen werden.</p>
</div>
<p>Mit <span class="math inline">\(P\)</span> und <span class="math inline">\(Q\)</span> können wir nun die <em>log odds</em> (den Logit) berechnen:</p>
<div class="sourceCode" id="cb353"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb353-1"><a href="logistische-regression.html#cb353-1" tabindex="-1"></a>df<span class="sc">$</span>log_odds <span class="ot">&lt;-</span> <span class="fu">log</span>(df<span class="sc">$</span>P<span class="sc">/</span>df<span class="sc">$</span>Q)</span>
<span id="cb353-2"><a href="logistische-regression.html#cb353-2" tabindex="-1"></a>df</span></code></pre></div>
<pre><code>## # A tibble: 6 × 4
##    Jahr     P     Q log_odds
##   &lt;int&gt; &lt;int&gt; &lt;int&gt;    &lt;dbl&gt;
## 1  1950     5    30   -1.79 
## 2  1960    21    18    0.154
## 3  1971    26    15    0.550
## 4  1980    20    13    0.431
## 5  1993    32     4    2.08 
## 6  2005    34     2    2.83</code></pre>
<p>Schauen wir uns die Verteilung der <em>log odds</em> über die Jahrzehnte an:</p>
<div class="sourceCode" id="cb355"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb355-1"><a href="logistische-regression.html#cb355-1" tabindex="-1"></a><span class="fu">ggplot</span>(df) <span class="sc">+</span> </span>
<span id="cb355-2"><a href="logistische-regression.html#cb355-2" tabindex="-1"></a>  <span class="fu">aes</span>(<span class="at">x =</span> Jahr, <span class="at">y =</span> log_odds) <span class="sc">+</span> </span>
<span id="cb355-3"><a href="logistische-regression.html#cb355-3" tabindex="-1"></a>  <span class="fu">geom_point</span>()</span></code></pre></div>
<p><img src="statistik_r_files/figure-html/unnamed-chunk-144-1.svg" width="672" /></p>
<p>Es sind diese <em>log odds</em>, durch die wir mittels der logistischen Regression eine Regressionslinie legen werden. Diese Regressionslinie wird genauso definiert wie die lineare Regressionslinie, sie schätzt aber eben die <em>log odds</em>:</p>
<p><span class="math inline">\(log(\frac{P}{Q}) = bx + k\)</span></p>
<p>Hier gilt wieder:</p>
<ul>
<li><span class="math inline">\(b\)</span> ist die Steigung</li>
<li><span class="math inline">\(x\)</span> ist ein Wert auf der x-Achse</li>
<li><span class="math inline">\(k\)</span> ist der y-Achsenabschnitt</li>
</ul>
<p>Hier können wir <span class="math inline">\(b\)</span> und <span class="math inline">\(k\)</span> jedoch nicht so leicht berechnen wie bei der linearen Regression, d.h. wir lassen sie uns direkt schätzen.</p>
</div>
<div id="die-logistische-regressionslinie" class="section level3 hasAnchor" number="6.2.2">
<h3><span class="header-section-number">6.2.2</span> Die logistische Regressionslinie<a href="logistische-regression.html#die-logistische-regressionslinie" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Bei der linearen Regression haben wir uns die Regressionskoeffizienten mit der Funktion <code>lm()</code> schätzen lassen, die dafür das <em>least squares</em> Verfahren benutzt. Die <strong>logistische Regressionslinie</strong> wird hingegen mit dem <strong>maximum likelihood</strong> Verfahren angenähert, das dafür sorgt, dass die geschätzten Datenpunkte des logistischen Modells so ähnlich wie möglich zu den tatsächlichen Werten sind. Zur Schätzung der Regressionskoeffizienten nutzen wir die Funktion <code>glm()</code>, das steht für <strong>Generalized Linear Model</strong>. Die Funktion bekommt neben der Formel <code>y ~ x</code> und dem Data Frame das Argument <code>family = binomial</code>, das der Funktion mitteilt, dass die Logit-Transformation durchgeführt werden soll. Die abhängige Variable muss ein Faktor sein; ggf. müssen Sie die Variable also mit <code>as.factor()</code> noch in einen Faktor verwandeln:</p>
<div class="sourceCode" id="cb356"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb356-1"><a href="logistische-regression.html#cb356-1" tabindex="-1"></a><span class="fu">class</span>(ovokal<span class="sc">$</span>Vokal) <span class="co"># kein Faktor</span></span></code></pre></div>
<pre><code>## [1] &quot;character&quot;</code></pre>
<div class="sourceCode" id="cb358"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb358-1"><a href="logistische-regression.html#cb358-1" tabindex="-1"></a>lreg <span class="ot">&lt;-</span> <span class="fu">glm</span>(<span class="fu">as.factor</span>(Vokal) <span class="sc">~</span> Jahr, <span class="at">family =</span> binomial, <span class="at">data =</span> ovokal)</span></code></pre></div>
<p>Die Zusammenfassung dieses Modells schauen wir uns etwas später an. Zuerst zeigen wir hier noch die Alternative zu der obigen Anwendung von <code>glm()</code> auf den originalen Daten Frame. <code>glm()</code> kann auch auf <span class="math inline">\(P\)</span> und <span class="math inline">\(Q\)</span> aus dem zusammengefassten Data Frame <code>df</code> ausgeführt werden, indem <span class="math inline">\(P\)</span> und <span class="math inline">\(Q\)</span> durch <code>cbind()</code> verbunden und als abhängige Variable verwendet werden:</p>
<div class="sourceCode" id="cb359"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb359-1"><a href="logistische-regression.html#cb359-1" tabindex="-1"></a>lreg2 <span class="ot">&lt;-</span> <span class="fu">glm</span>(<span class="fu">cbind</span>(P, Q) <span class="sc">~</span> Jahr, <span class="at">family =</span> binomial, <span class="at">data =</span> df)</span></code></pre></div>
<p>Wir können wieder <code>coef()</code> verwenden, um uns die Regressionskoeffizienten (<em>Intercept</em> und <em>Slope</em>) anzeigen zu lassen:</p>
<div class="sourceCode" id="cb360"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb360-1"><a href="logistische-regression.html#cb360-1" tabindex="-1"></a>coefs <span class="ot">&lt;-</span> <span class="fu">coef</span>(lreg)</span>
<span id="cb360-2"><a href="logistische-regression.html#cb360-2" tabindex="-1"></a>coefs</span></code></pre></div>
<pre><code>## (Intercept)        Jahr 
##  -138.11742     0.07026</code></pre>
<div class="sourceCode" id="cb362"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb362-1"><a href="logistische-regression.html#cb362-1" tabindex="-1"></a><span class="co"># oder mit $coefficients</span></span>
<span id="cb362-2"><a href="logistische-regression.html#cb362-2" tabindex="-1"></a>lreg<span class="sc">$</span>coefficients</span></code></pre></div>
<pre><code>## (Intercept)        Jahr 
##  -138.11742     0.07026</code></pre>
<p>Mithilfe dieser Maße kann die gerade Regressionslinie auf die Daten im Logit-Raum überlagert werden. Dazu nutzen wir wieder die beiden Möglichkeiten aus <code>ggplot2</code>. Wenn <code>geom_smooth()</code> benutzt wird, muss <code>method = "glm"</code> verwendet werden, und bei <code>geom_abline()</code> benutzen wir die geschätzten <code>coefs</code> für <em>intercept</em> und <em>slope</em>.</p>
<div class="sourceCode" id="cb364"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb364-1"><a href="logistische-regression.html#cb364-1" tabindex="-1"></a><span class="co"># mit geom_smooth():</span></span>
<span id="cb364-2"><a href="logistische-regression.html#cb364-2" tabindex="-1"></a><span class="fu">ggplot</span>(df) <span class="sc">+</span> </span>
<span id="cb364-3"><a href="logistische-regression.html#cb364-3" tabindex="-1"></a>  <span class="fu">aes</span>(<span class="at">x =</span> Jahr, <span class="at">y =</span> log_odds) <span class="sc">+</span> </span>
<span id="cb364-4"><a href="logistische-regression.html#cb364-4" tabindex="-1"></a>  <span class="fu">geom_point</span>() <span class="sc">+</span> </span>
<span id="cb364-5"><a href="logistische-regression.html#cb364-5" tabindex="-1"></a>  <span class="fu">geom_smooth</span>(<span class="at">method =</span> <span class="st">&quot;glm&quot;</span>, <span class="at">se =</span> F)</span></code></pre></div>
<pre><code>## `geom_smooth()` using formula = &#39;y ~ x&#39;</code></pre>
<p><img src="statistik_r_files/figure-html/unnamed-chunk-148-1.svg" width="672" /></p>
<div class="sourceCode" id="cb366"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb366-1"><a href="logistische-regression.html#cb366-1" tabindex="-1"></a><span class="co"># mit geom_abline():</span></span>
<span id="cb366-2"><a href="logistische-regression.html#cb366-2" tabindex="-1"></a><span class="fu">ggplot</span>(df) <span class="sc">+</span> </span>
<span id="cb366-3"><a href="logistische-regression.html#cb366-3" tabindex="-1"></a>  <span class="fu">aes</span>(<span class="at">x =</span> Jahr, <span class="at">y =</span> log_odds) <span class="sc">+</span> </span>
<span id="cb366-4"><a href="logistische-regression.html#cb366-4" tabindex="-1"></a>  <span class="fu">geom_point</span>() <span class="sc">+</span> </span>
<span id="cb366-5"><a href="logistische-regression.html#cb366-5" tabindex="-1"></a>  <span class="fu">geom_abline</span>(<span class="at">intercept =</span> coefs[<span class="dv">1</span>], <span class="at">slope =</span> coefs[<span class="dv">2</span>], <span class="at">color =</span> <span class="st">&quot;blue&quot;</span>)</span></code></pre></div>
<p><img src="statistik_r_files/figure-html/unnamed-chunk-148-2.svg" width="672" /></p>
<p>Die Werte, die durch die logistische Regression geschätzt werden, sind die <em>log odds</em>. Wir können wieder die Funktion <code>predict()</code> verwenden, um uns die geschätzten <em>log odds</em> anzeigen zu lassen:</p>
<div class="sourceCode" id="cb367"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb367-1"><a href="logistische-regression.html#cb367-1" tabindex="-1"></a>log_odds_estimate <span class="ot">&lt;-</span> <span class="fu">predict</span>(lreg)</span>
<span id="cb367-2"><a href="logistische-regression.html#cb367-2" tabindex="-1"></a>log_odds_estimate</span></code></pre></div>
<pre><code>##       1       2       3       4       5       6 
## -1.1043 -1.1043 -1.1043 -1.1043 -1.1043 -1.1043 
##       7       8       9      10      11      12 
## -1.1043 -1.1043 -1.1043 -1.1043 -1.1043 -1.1043 
##      13      14      15      16      17      18 
## -1.1043 -1.1043 -1.1043 -1.1043 -1.1043 -1.1043 
##      19      20      21      22      23      24 
## -1.1043 -1.1043 -1.1043 -1.1043 -1.1043 -1.1043 
##      25      26      27      28      29      30 
## -1.1043 -1.1043 -1.1043 -1.1043 -1.1043 -1.1043 
##      31      32      33      34      35      36 
## -1.1043 -1.1043 -1.1043 -1.1043 -1.1043 -0.4017 
##      37      38      39      40      41      42 
## -0.4017 -0.4017 -0.4017 -0.4017 -0.4017 -0.4017 
##      43      44      45      46      47      48 
## -0.4017 -0.4017 -0.4017 -0.4017 -0.4017 -0.4017 
##      49      50      51      52      53      54 
## -0.4017 -0.4017 -0.4017 -0.4017 -0.4017 -0.4017 
##      55      56      57      58      59      60 
## -0.4017 -0.4017 -0.4017 -0.4017 -0.4017 -0.4017 
##      61      62      63      64      65      66 
## -0.4017 -0.4017 -0.4017 -0.4017 -0.4017 -0.4017 
##      67      68      69      70      71      72 
## -0.4017 -0.4017 -0.4017 -0.4017 -0.4017 -0.4017 
##      73      74      75      76      77      78 
## -0.4017 -0.4017  0.3712  0.3712  0.3712  0.3712 
##      79      80      81      82      83      84 
##  0.3712  0.3712  0.3712  0.3712  0.3712  0.3712 
##      85      86      87      88      89      90 
##  0.3712  0.3712  0.3712  0.3712  0.3712  0.3712 
##      91      92      93      94      95      96 
##  0.3712  0.3712  0.3712  0.3712  0.3712  0.3712 
##      97      98      99     100     101     102 
##  0.3712  0.3712  0.3712  0.3712  0.3712  0.3712 
##     103     104     105     106     107     108 
##  0.3712  0.3712  0.3712  0.3712  0.3712  0.3712 
##     109     110     111     112     113     114 
##  0.3712  0.3712  0.3712  0.3712  0.3712  0.3712 
##     115     116     117     118     119     120 
##  0.3712  1.0036  1.0036  1.0036  1.0036  1.0036 
##     121     122     123     124     125     126 
##  1.0036  1.0036  1.0036  1.0036  1.0036  1.0036 
##     127     128     129     130     131     132 
##  1.0036  1.0036  1.0036  1.0036  1.0036  1.0036 
##     133     134     135     136     137     138 
##  1.0036  1.0036  1.0036  1.0036  1.0036  1.0036 
##     139     140     141     142     143     144 
##  1.0036  1.0036  1.0036  1.0036  1.0036  1.0036 
##     145     146     147     148     149     150 
##  1.0036  1.0036  1.0036  1.0036  1.9170  1.9170 
##     151     152     153     154     155     156 
##  1.9170  1.9170  1.9170  1.9170  1.9170  1.9170 
##     157     158     159     160     161     162 
##  1.9170  1.9170  1.9170  1.9170  1.9170  1.9170 
##     163     164     165     166     167     168 
##  1.9170  1.9170  1.9170  1.9170  1.9170  1.9170 
##     169     170     171     172     173     174 
##  1.9170  1.9170  1.9170  1.9170  1.9170  1.9170 
##     175     176     177     178     179     180 
##  1.9170  1.9170  1.9170  1.9170  1.9170  1.9170 
##     181     182     183     184     185     186 
##  1.9170  1.9170  1.9170  1.9170  2.7601  2.7601 
##     187     188     189     190     191     192 
##  2.7601  2.7601  2.7601  2.7601  2.7601  2.7601 
##     193     194     195     196     197     198 
##  2.7601  2.7601  2.7601  2.7601  2.7601  2.7601 
##     199     200     201     202     203     204 
##  2.7601  2.7601  2.7601  2.7601  2.7601  2.7601 
##     205     206     207     208     209     210 
##  2.7601  2.7601  2.7601  2.7601  2.7601  2.7601 
##     211     212     213     214     215     216 
##  2.7601  2.7601  2.7601  2.7601  2.7601  2.7601 
##     217     218     219     220 
##  2.7601  2.7601  2.7601  2.7601</code></pre>
<p>Der Output von <code>predict()</code> besteht in diesem Fall aus 220 Zahlen, eine Zahl pro Zeile im originalen Data Frame <code>ovokal</code>. Wie Sie sehen, wiederholen sich die geschätzten <em>log odds</em>. Das liegt daran, dass ein <em>log odd</em> Wert pro Stufe (bzw. Wert) der unabhängigen Variable berechnet wird, in diesem Fall gibt es also sechs einzigartige <em>log odd</em> Werte, einen pro Jahreszahl:</p>
<div class="sourceCode" id="cb369"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb369-1"><a href="logistische-regression.html#cb369-1" tabindex="-1"></a><span class="fu">unique</span>(log_odds_estimate)</span></code></pre></div>
<pre><code>## [1] -1.1043 -0.4017  0.3712  1.0036  1.9170  2.7601</code></pre>
<p>Wir können diese vorhergesagten Werte wieder in Rot in unserem <code>ggplot</code> von oben einzeichnen und stellen fest, dass die vorhergesagten Werte genau auf der Regressionslinie liegen (wir verwenden hier <code>geom_abline()</code>):</p>
<div class="sourceCode" id="cb371"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb371-1"><a href="logistische-regression.html#cb371-1" tabindex="-1"></a><span class="fu">ggplot</span>(df) <span class="sc">+</span> </span>
<span id="cb371-2"><a href="logistische-regression.html#cb371-2" tabindex="-1"></a>  <span class="fu">aes</span>(<span class="at">x =</span> Jahr, <span class="at">y =</span> log_odds) <span class="sc">+</span> </span>
<span id="cb371-3"><a href="logistische-regression.html#cb371-3" tabindex="-1"></a>  <span class="fu">geom_point</span>() <span class="sc">+</span> </span>
<span id="cb371-4"><a href="logistische-regression.html#cb371-4" tabindex="-1"></a>  <span class="fu">geom_abline</span>(<span class="at">intercept =</span> coefs[<span class="dv">1</span>], <span class="at">slope =</span> coefs[<span class="dv">2</span>], <span class="at">color =</span> <span class="st">&quot;blue&quot;</span>) <span class="sc">+</span></span>
<span id="cb371-5"><a href="logistische-regression.html#cb371-5" tabindex="-1"></a>  <span class="fu">geom_point</span>(<span class="at">data =</span> <span class="fu">data.frame</span>(<span class="at">x =</span> <span class="fu">unique</span>(ovokal<span class="sc">$</span>Jahr), <span class="at">y =</span> <span class="fu">unique</span>(log_odds_estimate)),</span>
<span id="cb371-6"><a href="logistische-regression.html#cb371-6" tabindex="-1"></a>             <span class="at">mapping =</span> <span class="fu">aes</span>(x, y),</span>
<span id="cb371-7"><a href="logistische-regression.html#cb371-7" tabindex="-1"></a>             <span class="at">color =</span> <span class="st">&quot;red&quot;</span>)</span></code></pre></div>
<p><img src="statistik_r_files/figure-html/unnamed-chunk-151-1.svg" width="672" /></p>
<p>Genau wie bei der linearen Regression können wir <code>predict()</code> auch benutzen, um uns die <em>log odds</em> Werte vorhersagen zu lassen für x-Werte, die nicht im originalen Datensatz vorkommen. Wenn wir uns zum Beispiel die Logit-Werte für die Jahre 2000 bis 2020 schätzen lassen wollen, funktioniert das wie folgt:</p>
<div class="sourceCode" id="cb372"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb372-1"><a href="logistische-regression.html#cb372-1" tabindex="-1"></a><span class="fu">predict</span>(lreg, <span class="fu">data.frame</span>(<span class="at">Jahr =</span> <span class="dv">2000</span><span class="sc">:</span><span class="dv">2020</span>))</span></code></pre></div>
<pre><code>##     1     2     3     4     5     6     7     8     9 
## 2.409 2.479 2.549 2.620 2.690 2.760 2.830 2.901 2.971 
##    10    11    12    13    14    15    16    17    18 
## 3.041 3.111 3.182 3.252 3.322 3.393 3.463 3.533 3.603 
##    19    20    21 
## 3.674 3.744 3.814</code></pre>
</div>
<div id="regression-mit-glm" class="section level3 hasAnchor" number="6.2.3">
<h3><span class="header-section-number">6.2.3</span> Regression mit <code>glm()</code><a href="logistische-regression.html#regression-mit-glm" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Das Ergebnis der Funktion <code>glm()</code> ist ein Objekt mit den Klassen “glm” und “lm”:</p>
<div class="sourceCode" id="cb374"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb374-1"><a href="logistische-regression.html#cb374-1" tabindex="-1"></a><span class="fu">class</span>(lreg)</span></code></pre></div>
<pre><code>## [1] &quot;glm&quot; &quot;lm&quot;</code></pre>
<p>Nun wenden wir die <code>summary()</code>-Funktion auf das Ergebnis der logistischen Regression <code>lreg</code> an und schauen uns das Ergebnis wieder Zeile für Zeile an:</p>
<div class="sourceCode" id="cb376"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb376-1"><a href="logistische-regression.html#cb376-1" tabindex="-1"></a><span class="fu">summary</span>(lreg)</span></code></pre></div>
<pre><code>## 
## Call:
## glm(formula = as.factor(Vokal) ~ Jahr, family = binomial, data = ovokal)
## 
## Coefficients:
##              Estimate Std. Error z value Pr(&gt;|z|)    
## (Intercept) -138.1174    20.9988   -6.58  4.8e-11 ***
## Jahr           0.0703     0.0107    6.59  4.3e-11 ***
## ---
## Signif. codes:  
## 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## (Dispersion parameter for binomial family taken to be 1)
## 
##     Null deviance: 290.57  on 219  degrees of freedom
## Residual deviance: 229.45  on 218  degrees of freedom
## AIC: 233.5
## 
## Number of Fisher Scoring iterations: 4</code></pre>
<p>Die Zusammengassung beginnt wieder mit dem <em>Call</em>, also der Funktion, die verwendet wurde.</p>
<div id="deviance-residuals" class="section level4 hasAnchor" number="6.2.3.1">
<h4><span class="header-section-number">6.2.3.1</span> Deviance Residuals<a href="logistische-regression.html#deviance-residuals" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>Die <strong>Deviance Residuals</strong> sind die Unterschiede zwischen den tatsächlichen und den geschätzten Werten. Es werden uns hier wieder Minimum, Maximum, Median und der Wertebereich der mittleren 50% der <em>log odds</em> Werte angezeigt:</p>
<p><img src="img/glm2.png" style="width:60.0%" /></p>
<p>Im Gegensatz zu den Residuals aus der linearen Regression werden die <em>Deviance Residuals</em> aber als Logits ausgedrückt, das bedeutet u.a. dass sie nicht normalverteilt sein müssen. Wie bei den Residuals, können wir uns die <em>Deviance Residuals</em> mit <code>resid()</code> ausgeben lassen:</p>
<div class="sourceCode" id="cb378"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb378-1"><a href="logistische-regression.html#cb378-1" tabindex="-1"></a><span class="fu">resid</span>(lreg)</span></code></pre></div>
<pre><code>##       1       2       3       4       5       6 
## -0.7566 -0.7566 -0.7566 -0.7566 -0.7566 -0.7566 
##       7       8       9      10      11      12 
## -0.7566 -0.7566 -0.7566 -0.7566 -0.7566 -0.7566 
##      13      14      15      16      17      18 
## -0.7566 -0.7566 -0.7566 -0.7566 -0.7566 -0.7566 
##      19      20      21      22      23      24 
## -0.7566 -0.7566 -0.7566 -0.7566 -0.7566 -0.7566 
##      25      26      27      28      29      30 
## -0.7566 -0.7566 -0.7566 -0.7566 -0.7566 -0.7566 
##      31      32      33      34      35      36 
##  1.6677  1.6677  1.6677  1.6677  1.6677 -1.0123 
##      37      38      39      40      41      42 
## -1.0123 -1.0123 -1.0123 -1.0123 -1.0123 -1.0123 
##      43      44      45      46      47      48 
## -1.0123 -1.0123 -1.0123 -1.0123 -1.0123 -1.0123 
##      49      50      51      52      53      54 
## -1.0123 -1.0123 -1.0123 -1.0123 -1.0123  1.3521 
##      55      56      57      58      59      60 
##  1.3521  1.3521  1.3521  1.3521  1.3521  1.3521 
##      61      62      63      64      65      66 
##  1.3521  1.3521  1.3521  1.3521  1.3521  1.3521 
##      67      68      69      70      71      72 
##  1.3521  1.3521  1.3521  1.3521  1.3521  1.3521 
##      73      74      75      76      77      78 
##  1.3521  1.3521 -1.3386 -1.3386 -1.3386 -1.3386 
##      79      80      81      82      83      84 
## -1.3386 -1.3386 -1.3386 -1.3386 -1.3386 -1.3386 
##      85      86      87      88      89      90 
## -1.3386 -1.3386 -1.3386 -1.3386 -1.3386  1.0244 
##      91      92      93      94      95      96 
##  1.0244  1.0244  1.0244  1.0244  1.0244  1.0244 
##      97      98      99     100     101     102 
##  1.0244  1.0244  1.0244  1.0244  1.0244  1.0244 
##     103     104     105     106     107     108 
##  1.0244  1.0244  1.0244  1.0244  1.0244  1.0244 
##     109     110     111     112     113     114 
##  1.0244  1.0244  1.0244  1.0244  1.0244  1.0244 
##     115     116     117     118     119     120 
##  1.0244 -1.6223 -1.6223 -1.6223 -1.6223 -1.6223 
##     121     122     123     124     125     126 
## -1.6223 -1.6223 -1.6223 -1.6223 -1.6223 -1.6223 
##     127     128     129     130     131     132 
## -1.6223 -1.6223  0.7903  0.7903  0.7903  0.7903 
##     133     134     135     136     137     138 
##  0.7903  0.7903  0.7903  0.7903  0.7903  0.7903 
##     139     140     141     142     143     144 
##  0.7903  0.7903  0.7903  0.7903  0.7903  0.7903 
##     145     146     147     148     149     150 
##  0.7903  0.7903  0.7903  0.7903 -2.0269 -2.0269 
##     151     152     153     154     155     156 
## -2.0269 -2.0269  0.5238  0.5238  0.5238  0.5238 
##     157     158     159     160     161     162 
##  0.5238  0.5238  0.5238  0.5238  0.5238  0.5238 
##     163     164     165     166     167     168 
##  0.5238  0.5238  0.5238  0.5238  0.5238  0.5238 
##     169     170     171     172     173     174 
##  0.5238  0.5238  0.5238  0.5238  0.5238  0.5238 
##     175     176     177     178     179     180 
##  0.5238  0.5238  0.5238  0.5238  0.5238  0.5238 
##     181     182     183     184     185     186 
##  0.5238  0.5238  0.5238  0.5238 -2.3755 -2.3755 
##     187     188     189     190     191     192 
##  0.3503  0.3503  0.3503  0.3503  0.3503  0.3503 
##     193     194     195     196     197     198 
##  0.3503  0.3503  0.3503  0.3503  0.3503  0.3503 
##     199     200     201     202     203     204 
##  0.3503  0.3503  0.3503  0.3503  0.3503  0.3503 
##     205     206     207     208     209     210 
##  0.3503  0.3503  0.3503  0.3503  0.3503  0.3503 
##     211     212     213     214     215     216 
##  0.3503  0.3503  0.3503  0.3503  0.3503  0.3503 
##     217     218     219     220 
##  0.3503  0.3503  0.3503  0.3503</code></pre>
</div>
<div id="coefficients" class="section level4 hasAnchor" number="6.2.3.2">
<h4><span class="header-section-number">6.2.3.2</span> Coefficients<a href="logistische-regression.html#coefficients" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>Es folgt wieder die Tabelle der Regressionskoeffizienten:</p>
<p><img src="img/glm3.png" style="width:60.0%" /></p>
<p>In der ersten Zeile dieser Tabelle stehen die Kennzahlen für Intercept, in der zweiten für Slope. In der ersten Spalte finden sich wieder die <em>Estimates</em> (Schätzungen) für die Regressionskoeffizienten, die mittels eines <em>maximum likelihood</em> Verfahrens ermittelt wurden. In der zweiten Spalte steht der Standard-Error, der beschreibt, wie verlässlich die Schätzungen sind (je kleiner desto besser). Auf die beiden Schätzungen wurde ein <strong>Wald Test</strong> durchgeführt, der prüft, ob sich die Schätzungen signifikant von Null unterscheiden. Das Ergebnis dieses Tests ist der <strong>z-value</strong>, der sich auch aus der Division von Estimate und Standard Error berechnen lässt. Hierbei interessiert uns vor allem die zweite Zeile, deren z-Wert und p-Wert zeigen, ob die unabhängige Variable <em>Jahr</em> in signifikantem Maß dazu beiträgt, die <em>log odds</em> Werte zu erklären. Wenn der p-Wert, der in der vierten Spalte steht, kleiner ist als 0.05 (siehe auch die Signifikanzniveau-Sternchen), dann unterscheidet sich der Koeffizient signifikant von Null. Im Fall der abhängigen Variable sehen wir, dass der p-Wert kleiner ist als 0.001, d.h. die Variable ist ein guter Prädiktor für die <em>log odds</em>.</p>
<p>Standardmäßig wird nach der <em>Coefficients</em>-Tabelle ein Statement über den <strong>Dispersion parameter</strong> gedruckt. Das können wir ignorieren.</p>
</div>
<div id="deviances-und-aic" class="section level4 hasAnchor" number="6.2.3.3">
<h4><span class="header-section-number">6.2.3.3</span> Deviances und AIC<a href="logistische-regression.html#deviances-und-aic" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>In den folgenden zwei Zeilen stehen die <strong>Null deviance</strong> und die <strong>Residual deviance</strong> sowie das <strong>AIC</strong> (<em>Akaike Information Criterion</em>):</p>
<p><img src="img/glm5.png" style="width:60.0%" /></p>
<p>Die <em>Null deviance</em> beschreibt, wie gut ein Modell ohne unabhängige Variablen die Daten erklären würde. Ein Modell ohne unabhängige Variablen wird nur durch das Intercept charakterisiert. Für sich alleine genommen ist die <em>Null deviance</em> schwierig zu interpretieren. Deshalb steht gleich darunter die <em>Residual deviance</em>, die beschreibt, wie gut das tatsächlich verwendete Modell die Daten erklären würde. Aus der Differenz zwischen <em>Null</em> und <em>Residual Deviance</em> lässt sich also erkennen, wie hilfreich unsere unabhängige Variable in dem Modell ist. Die Freiheitsgrade berechnen sich übrigens aus der Anzahl der Beobachtungen im Data Frame minus die Anzahl der Parameter im Modell. Bei der <em>Null deviance</em> gibt es nur einen Parameter (Intercept), bei der <em>Residual deviance</em> gibt es zwei (Intercept und unabhängige Variable). Je kleiner die Deviances (also die Abweichungen zwischen den tatsächlichen und den geschätzten Werten) sind, desto besser.</p>
<p><strong>AIC</strong> steht für <strong>Akaike Information Criterion</strong> und ist vor allem hilfreich, wenn man verschiedene Regressionsmodelle für dasselbe Datenset vergleichen will (wenn man also z.B. für <code>ovokal</code> noch ein Modell mit mehr als einer unabhängigen Variable berechnen würde). Je kleiner AIC, desto besser beschreibt das Modell die Varianz in den Daten. Da wir hier nur das eine Modell haben, ist AIC für uns uninteressant.</p>
</div>
<div id="fisher-scoring-iterations" class="section level4 hasAnchor" number="6.2.3.4">
<h4><span class="header-section-number">6.2.3.4</span> Fisher Scoring iterations<a href="logistische-regression.html#fisher-scoring-iterations" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>Bei der logistischen Regression berechnet ein iterativer Algorithmus die Regressionsparameter und die <strong>Fisher Scoring iterations</strong> geben Auskunft darüber, wie viele Iterationen benötigt wurden. Das ist ebenfalls uninteressant für uns.</p>
<p><img src="img/glm6.png" style="width:60.0%" /></p>
</div>
</div>
<div id="der-chi-square-test-ergebnisse-berichten" class="section level3 hasAnchor" number="6.2.4">
<h3><span class="header-section-number">6.2.4</span> Der Chi-Square Test &amp; Ergebnisse berichten<a href="logistische-regression.html#der-chi-square-test-ergebnisse-berichten" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Bei der linearen Regression haben wir als Prüfstatistik einen F-Test durchgeführt. Anstelle dessen führen wir bei der logistischen Regression einen <strong>Chi-Square Test</strong> durch, der prüft, ob das Modell einen signifikanten Anteil der Varianz in der abhängigen Variable erklärt. Da wir oben in der <em>Coefficients</em>-Tabelle schon gesehen haben, dass der Wald Test für unsere unabhängige Variable signifikant war, wird wahrscheinlich auch das gesamte Modell signifikant sein. Wir verwenden hierfür die Funktion <code>anova()</code> mit dem Argument <code>test = "Chisq</code>:</p>
<div class="sourceCode" id="cb380"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb380-1"><a href="logistische-regression.html#cb380-1" tabindex="-1"></a><span class="fu">anova</span>(lreg, <span class="at">test =</span> <span class="st">&quot;Chisq&quot;</span>)</span></code></pre></div>
<pre><code>## Analysis of Deviance Table
## 
## Model: binomial, link: logit
## 
## Response: as.factor(Vokal)
## 
## Terms added sequentially (first to last)
## 
## 
##      Df Deviance Resid. Df Resid. Dev Pr(&gt;Chi)    
## NULL                   219        291             
## Jahr  1     61.1       218        230  5.4e-15 ***
## ---
## Signif. codes:  
## 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<p>Das Ergebnis des Chi-Square Tests hat zwei Zeilen, eine für das Null-Modell (nur Intercept) und das andere für das Modell mit der unabhängigen Variable <em>Jahr</em>. In der Spalte <code>Resid. Df</code> finden sich die Freiheitsgrade für die <em>Null</em> und <em>Residual Deviance</em>, die wiederum in der Spalte <code>Resid. Dev.</code> angegeben werden. Diese Werte wurden in der Zusammenfassung des logistischen Modells in Kurzform berichtet. Uns interessiert aus dem Ergebnis des Chi-Square Tests vor allem der Wert in der Spalte <code>Pr(&gt;Chi)</code>, die den p-Wert enthält. Wenn dieser Wert kleiner ist als 0.05 (siehe auch Signifikanzsternchen), dann erklärt das Modell einen signifikanten Anteil der Variation in den Daten. Nachdem wir den Chi-Square Test durchgeführt haben, berichten wir folgende Kennzahlen: <strong><span class="math inline">\(\chi^2\)</span>[Df] = Deviance, p &lt; Signifikanzniveau</strong>.</p>
<p>Unsere Ausgangsfrage war: <em>Wird die Aussprache des Vokals (hoch vs. tief) vom Jahr beeinflusst?</em></p>
<p>Nun können wir also berichten: <em>Jahr hatte einen signifikanten Einfluss auf die Proportion von ‘lost’ mit tiefem/hohem Vokal (<span class="math inline">\(\chi^2\)</span>[1] = 61.1, p &lt; 0.001).</em></p>
</div>
</div>
<div id="die-sigmoidal-funktion-und-der-umkipppunkt" class="section level2 hasAnchor" number="6.3">
<h2><span class="header-section-number">6.3</span> Die Sigmoidal-Funktion und der Umkipppunkt<a href="logistische-regression.html#die-sigmoidal-funktion-und-der-umkipppunkt" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Die Ergebnisse einer logistischen Regression haben wir oben im Logit-Raum präsentiert. Man kann jedoch auch den y-Achsenabschnitt und die Steigung verwenden, um statt der <em>log odds</em> auf der y-Achse <strong>Proportionen</strong> abzubilden. In diesem Fall ist die Regressionslinie nicht mehr gerade, sondern <strong>sigmoidal</strong> (s-förmig). Die Formel für die Sigmoid-Funktion lautet:</p>
<p><span class="math inline">\(f(x) = \frac{e^{bx+k}}{1 + e^{bx+k}}\)</span></p>
<p>In dieser Formel ist <span class="math inline">\(e\)</span> ist die Exponentialfunktion, <span class="math inline">\(b\)</span> und <span class="math inline">\(k\)</span> sind die Steigung und das Intercept. Je größer die Steigung <span class="math inline">\(b\)</span> ist (in der Abbildung: 1, 0.5, 0.25), desto steiler kippt die Sigmoid-Kurve (schwarz, rot, grün):</p>
<p><img src="img/sigmoid_b.png" /></p>
<p>Wenn die Steigung Null ist, bekommt man eine gerade Linie um den Wert 0.5 auf der y-Achse. Wenn man bei einer Steigung von <span class="math inline">\(b = 0\)</span> den y-Achsenabschnitt <span class="math inline">\(k\)</span> verändert (in der Abbildung: 0, 1, -1), führt das dazu, dass die gerade horizontale Linie nach oben oder unten verschoben wird (schwarz, rot, grün):</p>
<p><img src="img/sigmoid_k.png" /></p>
<div id="der-umkipppunkt" class="section level3 hasAnchor" number="6.3.1">
<h3><span class="header-section-number">6.3.1</span> Der Umkipppunkt<a href="logistische-regression.html#der-umkipppunkt" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Der <strong>Umkipppunkt</strong> ist der Punkt, zu dem die Sigmoid-Kurve <strong>am steilsten</strong> ist. An diesem Punkt ist der Wert auf der y-Achse (die Proportion) immer 0.5 (unten als horizontale Linie). Den x-Wert des Umkipppunkts berechnet man mit <span class="math inline">\(\frac{-k}{b}\)</span>. Für <span class="math inline">\(k = 4\)</span> und <span class="math inline">\(b = 0.8\)</span> wäre das zum Beispiel <span class="math inline">\(-4/0.8 = -5\)</span> (hier als gestrichelte Linie):</p>
<p><img src="img/sigmoid.png" /></p>
</div>
<div id="proportionen-abbilden" class="section level3 hasAnchor" number="6.3.2">
<h3><span class="header-section-number">6.3.2</span> Proportionen abbilden<a href="logistische-regression.html#proportionen-abbilden" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Für unser Beispiel oben wollen wir nun Proportionen abbilden und anschließend eine sigmoidale Regressionskurve durch unsere Daten legen. Wir nehmen unseren zusammengefassten Data Frame <code>df</code> und berechnen die Proportion von <span class="math inline">\(P\)</span> (den Anteil von “Erfolgen”) pro Jahr:</p>
<div class="sourceCode" id="cb382"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb382-1"><a href="logistische-regression.html#cb382-1" tabindex="-1"></a>df<span class="sc">$</span>Proportion <span class="ot">&lt;-</span> df<span class="sc">$</span>P <span class="sc">/</span> (df<span class="sc">$</span>P <span class="sc">+</span> df<span class="sc">$</span>Q)</span>
<span id="cb382-2"><a href="logistische-regression.html#cb382-2" tabindex="-1"></a>df</span></code></pre></div>
<pre><code>## # A tibble: 6 × 5
##    Jahr     P     Q log_odds Proportion
##   &lt;int&gt; &lt;int&gt; &lt;int&gt;    &lt;dbl&gt;      &lt;dbl&gt;
## 1  1950     5    30   -1.79       0.143
## 2  1960    21    18    0.154      0.538
## 3  1971    26    15    0.550      0.634
## 4  1980    20    13    0.431      0.606
## 5  1993    32     4    2.08       0.889
## 6  2005    34     2    2.83       0.944</code></pre>
<p>Für das Jahr 1950 liegt der Anteil an “Erfolgen” (wo also der Vokal /o/ tief produziert wurde) bei 14.3%, für das Jahr 1960 dann schon bei 53.8% usw. Diese Proportionen in der neu angelegten Spalte <code>df$Proportion</code> können wir jetzt plotten und dann mittels <code>geom_smooth()</code> eine sigmoidale Regressionslinie durch die Daten legen. Die Funktion <code>glm()</code>, die von <code>geom_smooth(method = "glm")</code> verwendet wird, braucht als Argument aber noch <code>family = binomial</code>. Deshalb geben wir <code>geom_smooth()</code> noch das Argument <code>method.args</code>, das dieses Argument für die <code>glm()</code>-Funktion definiert.</p>
<div class="sourceCode" id="cb384"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb384-1"><a href="logistische-regression.html#cb384-1" tabindex="-1"></a><span class="fu">ggplot</span>(df) <span class="sc">+</span> </span>
<span id="cb384-2"><a href="logistische-regression.html#cb384-2" tabindex="-1"></a>  <span class="fu">aes</span>(<span class="at">x =</span> Jahr, <span class="at">y =</span> Proportion) <span class="sc">+</span> </span>
<span id="cb384-3"><a href="logistische-regression.html#cb384-3" tabindex="-1"></a>  <span class="fu">geom_point</span>() <span class="sc">+</span> </span>
<span id="cb384-4"><a href="logistische-regression.html#cb384-4" tabindex="-1"></a>  <span class="fu">geom_smooth</span>(<span class="at">method =</span> <span class="st">&quot;glm&quot;</span>, <span class="at">se =</span> F, <span class="at">method.args =</span> <span class="fu">list</span>(<span class="at">family =</span> binomial))</span></code></pre></div>
<pre><code>## `geom_smooth()` using formula = &#39;y ~ x&#39;</code></pre>
<pre><code>## Warning in eval(family$initialize): non-integer
## #successes in a binomial glm!</code></pre>
<p><img src="statistik_r_files/figure-html/unnamed-chunk-158-1.svg" width="672" /></p>
<p>In dieser Abbildung ist das vollständige “S” der sigmoidalen Kurve nicht zu erkennen, weil unser Ausschnitt auf der x-Achse zu klein ist. Wir können uns aber einfach weitere Proportionswerte mit <code>predict()</code> berechnen. Wie wir vorhin gesehen haben, gibt uns <code>predict()</code> aber die <em>log odds</em> aus, und nicht die Proportionen. Die Proportionen erhalten wir, wenn wir in <code>predict()</code> das Argument <code>type = "response"</code> nutzen:</p>
<div class="sourceCode" id="cb387"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb387-1"><a href="logistische-regression.html#cb387-1" tabindex="-1"></a><span class="fu">predict</span>(lreg, <span class="at">type =</span> <span class="st">&quot;response&quot;</span>)</span></code></pre></div>
<pre><code>##      1      2      3      4      5      6      7 
## 0.2489 0.2489 0.2489 0.2489 0.2489 0.2489 0.2489 
##      8      9     10     11     12     13     14 
## 0.2489 0.2489 0.2489 0.2489 0.2489 0.2489 0.2489 
##     15     16     17     18     19     20     21 
## 0.2489 0.2489 0.2489 0.2489 0.2489 0.2489 0.2489 
##     22     23     24     25     26     27     28 
## 0.2489 0.2489 0.2489 0.2489 0.2489 0.2489 0.2489 
##     29     30     31     32     33     34     35 
## 0.2489 0.2489 0.2489 0.2489 0.2489 0.2489 0.2489 
##     36     37     38     39     40     41     42 
## 0.4009 0.4009 0.4009 0.4009 0.4009 0.4009 0.4009 
##     43     44     45     46     47     48     49 
## 0.4009 0.4009 0.4009 0.4009 0.4009 0.4009 0.4009 
##     50     51     52     53     54     55     56 
## 0.4009 0.4009 0.4009 0.4009 0.4009 0.4009 0.4009 
##     57     58     59     60     61     62     63 
## 0.4009 0.4009 0.4009 0.4009 0.4009 0.4009 0.4009 
##     64     65     66     67     68     69     70 
## 0.4009 0.4009 0.4009 0.4009 0.4009 0.4009 0.4009 
##     71     72     73     74     75     76     77 
## 0.4009 0.4009 0.4009 0.4009 0.5917 0.5917 0.5917 
##     78     79     80     81     82     83     84 
## 0.5917 0.5917 0.5917 0.5917 0.5917 0.5917 0.5917 
##     85     86     87     88     89     90     91 
## 0.5917 0.5917 0.5917 0.5917 0.5917 0.5917 0.5917 
##     92     93     94     95     96     97     98 
## 0.5917 0.5917 0.5917 0.5917 0.5917 0.5917 0.5917 
##     99    100    101    102    103    104    105 
## 0.5917 0.5917 0.5917 0.5917 0.5917 0.5917 0.5917 
##    106    107    108    109    110    111    112 
## 0.5917 0.5917 0.5917 0.5917 0.5917 0.5917 0.5917 
##    113    114    115    116    117    118    119 
## 0.5917 0.5917 0.5917 0.7318 0.7318 0.7318 0.7318 
##    120    121    122    123    124    125    126 
## 0.7318 0.7318 0.7318 0.7318 0.7318 0.7318 0.7318 
##    127    128    129    130    131    132    133 
## 0.7318 0.7318 0.7318 0.7318 0.7318 0.7318 0.7318 
##    134    135    136    137    138    139    140 
## 0.7318 0.7318 0.7318 0.7318 0.7318 0.7318 0.7318 
##    141    142    143    144    145    146    147 
## 0.7318 0.7318 0.7318 0.7318 0.7318 0.7318 0.7318 
##    148    149    150    151    152    153    154 
## 0.7318 0.8718 0.8718 0.8718 0.8718 0.8718 0.8718 
##    155    156    157    158    159    160    161 
## 0.8718 0.8718 0.8718 0.8718 0.8718 0.8718 0.8718 
##    162    163    164    165    166    167    168 
## 0.8718 0.8718 0.8718 0.8718 0.8718 0.8718 0.8718 
##    169    170    171    172    173    174    175 
## 0.8718 0.8718 0.8718 0.8718 0.8718 0.8718 0.8718 
##    176    177    178    179    180    181    182 
## 0.8718 0.8718 0.8718 0.8718 0.8718 0.8718 0.8718 
##    183    184    185    186    187    188    189 
## 0.8718 0.8718 0.9405 0.9405 0.9405 0.9405 0.9405 
##    190    191    192    193    194    195    196 
## 0.9405 0.9405 0.9405 0.9405 0.9405 0.9405 0.9405 
##    197    198    199    200    201    202    203 
## 0.9405 0.9405 0.9405 0.9405 0.9405 0.9405 0.9405 
##    204    205    206    207    208    209    210 
## 0.9405 0.9405 0.9405 0.9405 0.9405 0.9405 0.9405 
##    211    212    213    214    215    216    217 
## 0.9405 0.9405 0.9405 0.9405 0.9405 0.9405 0.9405 
##    218    219    220 
## 0.9405 0.9405 0.9405</code></pre>
<p>Das sind jetzt wieder die geschätzten Werte für alle 220 Beobachtungen im originalen Data Frame. Wir wollen nun ein paar Schätzungen für die Jahre vor 1950 und nach 2010. Also geben wir der <code>predict()</code>-Funktion auch noch einen Data Frame mit den gewünschten Jahreszahlen:</p>
<div class="sourceCode" id="cb389"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb389-1"><a href="logistische-regression.html#cb389-1" tabindex="-1"></a>more_props <span class="ot">&lt;-</span> <span class="fu">predict</span>(lreg, <span class="fu">data.frame</span>(<span class="at">Jahr =</span> <span class="fu">c</span>(<span class="dv">1910</span>, <span class="dv">1920</span>, <span class="dv">1930</span>, <span class="dv">1940</span>, <span class="dv">2020</span>, <span class="dv">2030</span>)), <span class="at">type =</span> <span class="st">&quot;response&quot;</span>)</span>
<span id="cb389-2"><a href="logistische-regression.html#cb389-2" tabindex="-1"></a>more_props</span></code></pre></div>
<pre><code>##       1       2       3       4       5       6 
## 0.01955 0.03871 0.07519 0.14101 0.97842 0.98919</code></pre>
<p>Wir bauen uns nun einen Data Frame, der nur Jahr und Proportionen enthält, und zwar aus dem originalen Data Frame und den soeben geschätzten Werten:</p>
<div class="sourceCode" id="cb391"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb391-1"><a href="logistische-regression.html#cb391-1" tabindex="-1"></a>Jahr <span class="ot">&lt;-</span> <span class="fu">c</span>(df<span class="sc">$</span>Jahr, <span class="dv">1910</span>, <span class="dv">1920</span>, <span class="dv">1930</span>, <span class="dv">1940</span>, <span class="dv">2020</span>, <span class="dv">2030</span>)</span>
<span id="cb391-2"><a href="logistische-regression.html#cb391-2" tabindex="-1"></a>Proportion <span class="ot">&lt;-</span> <span class="fu">c</span>(df<span class="sc">$</span>Proportion, more_props)</span>
<span id="cb391-3"><a href="logistische-regression.html#cb391-3" tabindex="-1"></a>df <span class="ot">&lt;-</span> <span class="fu">data.frame</span>(Jahr, Proportion)</span>
<span id="cb391-4"><a href="logistische-regression.html#cb391-4" tabindex="-1"></a></span>
<span id="cb391-5"><a href="logistische-regression.html#cb391-5" tabindex="-1"></a><span class="fu">ggplot</span>(df) <span class="sc">+</span> </span>
<span id="cb391-6"><a href="logistische-regression.html#cb391-6" tabindex="-1"></a>  <span class="fu">aes</span>(<span class="at">x =</span> Jahr, <span class="at">y =</span> Proportion) <span class="sc">+</span> </span>
<span id="cb391-7"><a href="logistische-regression.html#cb391-7" tabindex="-1"></a>  <span class="fu">geom_point</span>() <span class="sc">+</span> </span>
<span id="cb391-8"><a href="logistische-regression.html#cb391-8" tabindex="-1"></a>  <span class="fu">geom_smooth</span>(<span class="at">method =</span> <span class="st">&quot;glm&quot;</span>, <span class="at">se =</span> F, <span class="at">method.args =</span> <span class="fu">list</span>(<span class="at">family =</span> binomial))</span></code></pre></div>
<pre><code>## `geom_smooth()` using formula = &#39;y ~ x&#39;</code></pre>
<pre><code>## Warning in eval(family$initialize): non-integer
## #successes in a binomial glm!</code></pre>
<p><img src="statistik_r_files/figure-html/unnamed-chunk-161-1.svg" width="672" /></p>
<p>Wir können für diese Daten auch noch den Umkipppunkt berechnen und zwar aus den oben bereits gespeicherten <code>coefs</code>:</p>
<div class="sourceCode" id="cb394"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb394-1"><a href="logistische-regression.html#cb394-1" tabindex="-1"></a><span class="sc">-</span>coefs[<span class="dv">1</span>] <span class="sc">/</span> coefs[<span class="dv">2</span>]</span></code></pre></div>
<pre><code>## (Intercept) 
##        1966</code></pre>
<p>Das Jahr, in dem sich die Aussprache von /o/ in der <em>Received Pronunciation</em> von “hoch” in “tief” wandelt, ist also laut unserem Modell ungefähr das Jahr 1965.</p>
</div>
</div>
<div id="umkipppunkte-in-perzeptionstests" class="section level2 hasAnchor" number="6.4">
<h2><span class="header-section-number">6.4</span> Umkipppunkte in Perzeptionstests<a href="logistische-regression.html#umkipppunkte-in-perzeptionstests" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Umkipppunkte werden häufig in Perzeptionstests verwendet, die wie folgt konstruiert werden: Wir haben ein 11-stufiges Kontinuum zwischen /pUp/ und /pYp/ synthetisiert. Phonetisch betrachtet ist der Unterschied zwischen /U/ und /Y/ der zweite Formant, der bei /U/ niedrig und bei /Y/ hoch ist. Diesen F2-Wert haben wir im Kontinuum also in 11 Schritten langsam verändert. Das erste und letzte Token aus diesem Kontinuum klingen sehr eindeutig wie PUPP oder PÜPP, dazwischen kann es aber schwierig für Hörer sein, zwischen PUPP und PÜPP zu unterscheiden. Nun wurde einigen Probanden jedes Token aus dem Kontinuum in randomisierter Reihenfolge vorgespielt und der Proband musste entscheiden, ob es sich um PUPP oder PÜPP handelte. Uns interessiert, ab welchem F2-Wert die Wahrnehmung der Probanden von PUPP auf PÜPP umschaltet. Anders gesagt: Uns interessiert hier der Umkipppunkt.</p>
<p>Daten aus einem solchen Perzeptionsexperiment haben wir im Data Frame <code>pvp</code> gespeichert:</p>
<div class="sourceCode" id="cb396"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb396-1"><a href="logistische-regression.html#cb396-1" tabindex="-1"></a><span class="fu">head</span>(pvp)</span></code></pre></div>
<pre><code>##    Vpn   F2 Urteil
## 1 VP18 1239      Y
## 2 VP18 1088      Y
## 3 VP18  803      U
## 4 VP18  956      U
## 5 VP18 1328      Y
## 6 VP18  861      U</code></pre>
<div class="sourceCode" id="cb398"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb398-1"><a href="logistische-regression.html#cb398-1" tabindex="-1"></a><span class="fu">levels</span>(pvp<span class="sc">$</span>Urteil)</span></code></pre></div>
<pre><code>## NULL</code></pre>
<div class="sourceCode" id="cb400"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb400-1"><a href="logistische-regression.html#cb400-1" tabindex="-1"></a><span class="fu">unique</span>(pvp<span class="sc">$</span>F2)</span></code></pre></div>
<pre><code>##  [1] 1239 1088  803  956 1328  861  989 1121  808 1310
## [11] 1436</code></pre>
<p>Wir erwarten, dass die Probanden mit steigendem F2-Wert eher /Y/ als /U/ hören, also kodieren wir das Urteil /Y/ als Erfolg und /U/ als Misserfolg:</p>
<div class="sourceCode" id="cb402"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb402-1"><a href="logistische-regression.html#cb402-1" tabindex="-1"></a>pvp<span class="sc">$</span>Erfolg <span class="ot">&lt;-</span> pvp<span class="sc">$</span>Urteil <span class="sc">==</span> <span class="st">&quot;Y&quot;</span></span>
<span id="cb402-2"><a href="logistische-regression.html#cb402-2" tabindex="-1"></a>pvp<span class="sc">$</span>Misserfolg <span class="ot">&lt;-</span> <span class="sc">!</span>pvp<span class="sc">$</span>Erfolg</span>
<span id="cb402-3"><a href="logistische-regression.html#cb402-3" tabindex="-1"></a><span class="fu">head</span>(pvp)</span></code></pre></div>
<pre><code>##    Vpn   F2 Urteil Erfolg Misserfolg
## 1 VP18 1239      Y   TRUE      FALSE
## 2 VP18 1088      Y   TRUE      FALSE
## 3 VP18  803      U  FALSE       TRUE
## 4 VP18  956      U  FALSE       TRUE
## 5 VP18 1328      Y   TRUE      FALSE
## 6 VP18  861      U  FALSE       TRUE</code></pre>
<p>Nun verwenden wir wieder <code>dplyr</code>, um <span class="math inline">\(P\)</span> und <span class="math inline">\(Q\)</span> zu berechnen:</p>
<div class="sourceCode" id="cb404"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb404-1"><a href="logistische-regression.html#cb404-1" tabindex="-1"></a>df <span class="ot">&lt;-</span> pvp <span class="sc">%&gt;%</span></span>
<span id="cb404-2"><a href="logistische-regression.html#cb404-2" tabindex="-1"></a>  <span class="fu">group_by</span>(F2) <span class="sc">%&gt;%</span></span>
<span id="cb404-3"><a href="logistische-regression.html#cb404-3" tabindex="-1"></a>  dplyr<span class="sc">::</span><span class="fu">summarise</span>(<span class="at">P =</span> <span class="fu">sum</span>(Erfolg), <span class="at">Q =</span> <span class="fu">sum</span>(Misserfolg))</span>
<span id="cb404-4"><a href="logistische-regression.html#cb404-4" tabindex="-1"></a>df</span></code></pre></div>
<pre><code>## # A tibble: 11 × 3
##       F2     P     Q
##    &lt;int&gt; &lt;int&gt; &lt;int&gt;
##  1   803     0    10
##  2   808     0    10
##  3   861     0    10
##  4   956     0    10
##  5   989     0    10
##  6  1088     2     8
##  7  1121     4     6
##  8  1239     9     1
##  9  1310     9     1
## 10  1328    10     0
## 11  1436    10     0</code></pre>
<p>Anschließend berechnen wir die Proportionen von <span class="math inline">\(P\)</span> und <span class="math inline">\(Q\)</span> und plotten die sigmoidale Regressionslinie in den Daten:</p>
<div class="sourceCode" id="cb406"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb406-1"><a href="logistische-regression.html#cb406-1" tabindex="-1"></a>df<span class="sc">$</span>Proportionen <span class="ot">&lt;-</span> df<span class="sc">$</span>P <span class="sc">/</span> (df<span class="sc">$</span>P <span class="sc">+</span> df<span class="sc">$</span>Q)</span>
<span id="cb406-2"><a href="logistische-regression.html#cb406-2" tabindex="-1"></a>df</span></code></pre></div>
<pre><code>## # A tibble: 11 × 4
##       F2     P     Q Proportionen
##    &lt;int&gt; &lt;int&gt; &lt;int&gt;        &lt;dbl&gt;
##  1   803     0    10          0  
##  2   808     0    10          0  
##  3   861     0    10          0  
##  4   956     0    10          0  
##  5   989     0    10          0  
##  6  1088     2     8          0.2
##  7  1121     4     6          0.4
##  8  1239     9     1          0.9
##  9  1310     9     1          0.9
## 10  1328    10     0          1  
## 11  1436    10     0          1</code></pre>
<div class="sourceCode" id="cb408"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb408-1"><a href="logistische-regression.html#cb408-1" tabindex="-1"></a><span class="fu">ggplot</span>(df) <span class="sc">+</span> </span>
<span id="cb408-2"><a href="logistische-regression.html#cb408-2" tabindex="-1"></a>  <span class="fu">aes</span>(<span class="at">x =</span> F2, <span class="at">y =</span> Proportionen) <span class="sc">+</span> </span>
<span id="cb408-3"><a href="logistische-regression.html#cb408-3" tabindex="-1"></a>  <span class="fu">geom_point</span>() <span class="sc">+</span> </span>
<span id="cb408-4"><a href="logistische-regression.html#cb408-4" tabindex="-1"></a>  <span class="fu">geom_smooth</span>(<span class="at">method =</span> <span class="st">&quot;glm&quot;</span>, <span class="at">se =</span> F, <span class="at">method.args =</span> <span class="fu">list</span>(<span class="at">family =</span> binomial))</span></code></pre></div>
<pre><code>## `geom_smooth()` using formula = &#39;y ~ x&#39;</code></pre>
<pre><code>## Warning in eval(family$initialize): non-integer
## #successes in a binomial glm!</code></pre>
<p><img src="statistik_r_files/figure-html/unnamed-chunk-166-1.svg" width="672" /></p>
<p>Um den Umkipppunkt dieser Sigmoid-Kurve zu ermitteln, berechnen wir das Generalized Linear Model:</p>
<div class="sourceCode" id="cb411"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb411-1"><a href="logistische-regression.html#cb411-1" tabindex="-1"></a>pvp.glm <span class="ot">&lt;-</span> <span class="fu">glm</span>(<span class="fu">as.factor</span>(Urteil) <span class="sc">~</span> F2, <span class="at">family =</span> binomial, <span class="at">data =</span> pvp)</span></code></pre></div>
<p>Mit den geschätzten Regressionskoeffizienten können wir jetzt den perzeptiven Umkipppunkt der Probanden berechnen:</p>
<div class="sourceCode" id="cb412"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb412-1"><a href="logistische-regression.html#cb412-1" tabindex="-1"></a>coefs <span class="ot">&lt;-</span> <span class="fu">coef</span>(pvp.glm)</span>
<span id="cb412-2"><a href="logistische-regression.html#cb412-2" tabindex="-1"></a><span class="sc">-</span>coefs[<span class="dv">1</span>] <span class="sc">/</span> coefs[<span class="dv">2</span>]</span></code></pre></div>
<pre><code>## (Intercept) 
##        1151</code></pre>
<p>Das heißt ab einem F2-Wert von ca. 1151 Hz hören die Probanden eher PÜPP als PUPP.</p>
<p>Zuletzt wollen wir noch herausfinden, ob die Urteile der Probanden tatsächlich durch F2 beeinflusst wurden. Dafür nutzen wir den Chi-Square Test:</p>
<div class="sourceCode" id="cb414"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb414-1"><a href="logistische-regression.html#cb414-1" tabindex="-1"></a><span class="fu">anova</span>(pvp.glm, <span class="at">test =</span> <span class="st">&quot;Chisq&quot;</span>)</span></code></pre></div>
<pre><code>## Analysis of Deviance Table
## 
## Model: binomial, link: logit
## 
## Response: as.factor(Urteil)
## 
## Terms added sequentially (first to last)
## 
## 
##      Df Deviance Resid. Df Resid. Dev Pr(&gt;Chi)    
## NULL                   109      148.1             
## F2    1      109       108       39.1   &lt;2e-16 ***
## ---
## Signif. codes:  
## 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<p>Wir berichten: <em>Die Proportion von pUp/pYp-Antworten wurde signifikant von F2 beeinflusst (<span class="math inline">\(\chi^2\)</span>[1] = 109.0, p &lt; 0.001).</em></p>
</div>
<div id="kategorialer-unabhängiger-faktor" class="section level2 hasAnchor" number="6.5">
<h2><span class="header-section-number">6.5</span> Kategorialer unabhängiger Faktor<a href="#kategorialer-unabh%C3%A4ngiger-faktor" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Die logistische Regression kann auf eine ähnliche Weise verwendet werden, wenn die <strong>unabhängige Variable kategorial</strong> ist. Der wesentliche Unterschied ist, dass kein Umkipppunkt berechnet und kein Sigmoid abgebildet werden muss.</p>
<p>Im Data Frame <code>sz</code> haben wir Informationen darüber abgespeichert, wie 20 Versuchspersonen das Wort “Sonne” aussprechen: entweder mit initialem [s] (stimmlos) oder initialem [z] (stimmhaft). Von den 20 Versuchspersonen kamen 9 aus Bayern und 11 aus Schleswig-Holstein:</p>
<div class="sourceCode" id="cb416"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb416-1"><a href="logistische-regression.html#cb416-1" tabindex="-1"></a><span class="fu">head</span>(sz)</span></code></pre></div>
<pre><code>##   Frikativ Dialekt Vpn
## 1        z      SH  S1
## 2        z      SH  S2
## 3        z      SH  S3
## 4        z      SH  S4
## 5        s      SH  S5
## 6        s      SH  S6</code></pre>
<p>Unsere Frage ist nun: <em>Wird die Stimmhaftigkeit (zwei Stufen: s, z) vom Dialekt (zwei Stufen: BY, SH) beeinflusst?</em></p>
<p>Da beide Variablen in diesem Fall kategorial sind, können wir einen Barplot erstellen, um einen Eindruck von den Daten zu gewinnen:</p>
<div class="sourceCode" id="cb418"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb418-1"><a href="logistische-regression.html#cb418-1" tabindex="-1"></a><span class="fu">ggplot</span>(sz) <span class="sc">+</span> </span>
<span id="cb418-2"><a href="logistische-regression.html#cb418-2" tabindex="-1"></a>  <span class="fu">aes</span>(<span class="at">fill =</span> Frikativ, <span class="at">x =</span> Dialekt) <span class="sc">+</span> </span>
<span id="cb418-3"><a href="logistische-regression.html#cb418-3" tabindex="-1"></a>  <span class="fu">geom_bar</span>(<span class="at">position =</span> <span class="st">&quot;fill&quot;</span>)</span></code></pre></div>
<p><img src="statistik_r_files/figure-html/unnamed-chunk-171-1.svg" width="672" /></p>
<p>Es sieht sehr danach aus, dass der initiale Frikativ deutlich häufiger stimmlos in Bayern als in Schleswig-Holstein produziert wird. Nun wenden wir, genau wie zuvor, eine logistische Regression mit anschließendem Chi-Square Test auf die Daten an:</p>
<div class="sourceCode" id="cb419"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb419-1"><a href="logistische-regression.html#cb419-1" tabindex="-1"></a>sz.glm <span class="ot">&lt;-</span> <span class="fu">glm</span>(<span class="fu">as.factor</span>(Frikativ) <span class="sc">~</span> Dialekt, <span class="at">family =</span> binomial, <span class="at">data =</span> sz)</span>
<span id="cb419-2"><a href="logistische-regression.html#cb419-2" tabindex="-1"></a><span class="fu">anova</span>(sz.glm, <span class="at">test =</span> <span class="st">&quot;Chisq&quot;</span>)</span></code></pre></div>
<pre><code>## Analysis of Deviance Table
## 
## Model: binomial, link: logit
## 
## Response: as.factor(Frikativ)
## 
## Terms added sequentially (first to last)
## 
## 
##         Df Deviance Resid. Df Resid. Dev Pr(&gt;Chi)  
## NULL                       19       27.7           
## Dialekt  1      5.3        18       22.4    0.021 *
## ---
## Signif. codes:  
## 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<p>Der Chi-Square Test zeigt: <em>Die Verteilung von stimmhaftem und stimmlosen /s/ in Worten wie Sonne wurde signifikant vom Dialekt beeinflusst (<span class="math inline">\(\chi^2\)</span>[1] = 5.3, p &lt; 0.05).</em></p>

</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="gemischte-lineare-regression.html" class="navigation navigation-prev navigation-unique" aria-label="Previous page"><i class="fa fa-angle-left"></i></a>

    </div>
  </div>
<script src="libs/gitbook/js/app.min.js"></script>
<script src="libs/gitbook/js/clipboard.min.js"></script>
<script src="libs/gitbook/js/plugin-search.js"></script>
<script src="libs/gitbook/js/plugin-sharing.js"></script>
<script src="libs/gitbook/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook/js/plugin-bookdown.js"></script>
<script src="libs/gitbook/js/jquery.highlight.js"></script>
<script src="libs/gitbook/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
  "sharing": null,
  "fontsettings": {
    "theme": "white",
    "family": "sans",
    "size": 2
  },
  "edit": null,
  "history": {
    "link": null,
    "text": null
  },
  "view": {
    "link": null,
    "text": null
  },
  "download": null,
  "search": {
    "engine": "fuse",
    "options": null
  },
  "toc": {
    "collapse": "none",
    "scroll_highlight": true
  },
  "toolbar": {
    "position": "fixed"
  },
  "info": false
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.9/latest.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
